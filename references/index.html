<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        <link rel="canonical" href="https://github.com/akekic/causal-component-analysis/references/">
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>API - Causal Component Analysis</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css">
        <link href="../assets/_mkdocstrings.css" rel="stylesheet">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="..">Causal Component Analysis</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href=".." class="nav-link">About</a>
                            </li>
                            <li class="navitem active">
                                <a href="./" class="nav-link">API</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href=".." class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" class="nav-link disabled">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#api-references" class="nav-link">API references</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#data_generator" class="nav-link">data_generator</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#data_generator.data_module" class="nav-link">data_module</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#data_generator.graph_sampler" class="nav-link">graph_sampler</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#data_generator.mixing_function" class="nav-link">mixing_function</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#data_generator.multi_env_gdp" class="nav-link">multi_env_gdp</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#data_generator.noise_generator" class="nav-link">noise_generator</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#data_generator.scm" class="nav-link">scm</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#model" class="nav-link">model</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#model.cauca_model" class="nav-link">cauca_model</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#model.encoder" class="nav-link">encoder</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#model.normalizing_flow" class="nav-link">normalizing_flow</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="api-references">API references</h1>


<div class="doc doc-object doc-module">



<a id="data_generator"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">










<div class="doc doc-object doc-module">




<h2 id="data_generator.data_module" class="doc doc-heading">
          <code>data_module</code>


</h2>

  <div class="doc doc-contents ">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">




<h3 id="data_generator.data_module.MultiEnvDataModule" class="doc doc-heading">
          <code>MultiEnvDataModule</code>


</h3>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><span title="pytorch_lightning.LightningDataModule">LightningDataModule</span></code></p>

  
      <p>Data module for multi-environment data.</p>
<h5 id="data_generator.data_module.MultiEnvDataModule--attributes">Attributes</h5>
<p>medgp: MultiEnvDGP
    Multi-environment data generating process.
num_samples_per_env: int
    Number of samples per environment.
batch_size: int
    Batch size.
num_workers: int
    Number of workers for the data loaders.
intervention_targets_per_env: Tensor, shape (num_envs, num_causal_variables)
    Intervention targets per environment, with 1 indicating that the variable is intervened on.
log_dir: Optional[Path]
    Directory to save summary statistics and plots to. Default: None.
intervention_target_misspec: bool
    Whether to misspecify the intervention targets. If true, the intervention targets are permuted.
    I.e. the model received the wrong intervention targets. Default: False.
intervention_target_perm: Optional[list[int]]
    Permutation of the intervention targets. If None, a random permutation is used. Only used if
    intervention_target_misspec is True. Default: None.</p>
<h5 id="data_generator.data_module.MultiEnvDataModule--methods">Methods</h5>
<p>setup(stage=None) -&gt; None
    Setup the data module. This is where the data is sampled.
train_dataloader() -&gt; DataLoader
    Return the training data loader.
val_dataloader() -&gt; DataLoader
    Return the validation data loader.
test_dataloader() -&gt; DataLoader
    Return the test data loader.</p>

            <details class="quote">
              <summary>Source code in <code>data_generator/data_module.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MultiEnvDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Data module for multi-environment data.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    medgp: MultiEnvDGP</span>
<span class="sd">        Multi-environment data generating process.</span>
<span class="sd">    num_samples_per_env: int</span>
<span class="sd">        Number of samples per environment.</span>
<span class="sd">    batch_size: int</span>
<span class="sd">        Batch size.</span>
<span class="sd">    num_workers: int</span>
<span class="sd">        Number of workers for the data loaders.</span>
<span class="sd">    intervention_targets_per_env: Tensor, shape (num_envs, num_causal_variables)</span>
<span class="sd">        Intervention targets per environment, with 1 indicating that the variable is intervened on.</span>
<span class="sd">    log_dir: Optional[Path]</span>
<span class="sd">        Directory to save summary statistics and plots to. Default: None.</span>
<span class="sd">    intervention_target_misspec: bool</span>
<span class="sd">        Whether to misspecify the intervention targets. If true, the intervention targets are permuted.</span>
<span class="sd">        I.e. the model received the wrong intervention targets. Default: False.</span>
<span class="sd">    intervention_target_perm: Optional[list[int]]</span>
<span class="sd">        Permutation of the intervention targets. If None, a random permutation is used. Only used if</span>
<span class="sd">        intervention_target_misspec is True. Default: None.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    setup(stage=None) -&gt; None</span>
<span class="sd">        Setup the data module. This is where the data is sampled.</span>
<span class="sd">    train_dataloader() -&gt; DataLoader</span>
<span class="sd">        Return the training data loader.</span>
<span class="sd">    val_dataloader() -&gt; DataLoader</span>
<span class="sd">        Return the validation data loader.</span>
<span class="sd">    test_dataloader() -&gt; DataLoader</span>
<span class="sd">        Return the test data loader.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">multi_env_dgp</span><span class="p">:</span> <span class="n">MultiEnvDGP</span><span class="p">,</span>
        <span class="n">num_samples_per_env</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">log_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Path</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">intervention_target_misspec</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">intervention_target_perm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">medgp</span> <span class="o">=</span> <span class="n">multi_env_dgp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_samples_per_env</span> <span class="o">=</span> <span class="n">num_samples_per_env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">=</span> <span class="n">num_workers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intervention_targets_per_env</span> <span class="o">=</span> <span class="n">intervention_targets_per_env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">=</span> <span class="n">log_dir</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">intervention_target_misspec</span> <span class="o">=</span> <span class="n">intervention_target_misspec</span>
        <span class="n">latent_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">medgp</span><span class="o">.</span><span class="n">latent_scm</span><span class="o">.</span><span class="n">latent_dim</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">intervention_target_perm</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">intervention_target_perm</span><span class="p">)</span> <span class="o">==</span> <span class="n">latent_dim</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intervention_target_perm</span> <span class="o">=</span> <span class="n">intervention_target_perm</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">latent_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">medgp</span><span class="o">.</span><span class="n">latent_scm</span><span class="o">.</span><span class="n">latent_dim</span>
        <span class="n">num_envs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">intervention_targets_per_env</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">intervention_targets</span><span class="p">,</span> <span class="n">log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">medgp</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_samples_per_env</span><span class="p">,</span>
            <span class="n">intervention_targets_per_env</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">intervention_targets_per_env</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">intervention_target_misspec</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="n">num_envs</span> <span class="o">==</span> <span class="n">latent_dim</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="p">),</span> <span class="s2">&quot;only works if num_envs == num_causal_variables + 1&quot;</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">intervention_target_perm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">perm</span> <span class="o">=</span> <span class="n">random_perm</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">intervention_target_perm</span> <span class="o">=</span> <span class="n">perm</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">perm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">intervention_target_perm</span>

            <span class="c1"># remember where old targets were</span>
            <span class="n">idx_mask_list</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">):</span>
                <span class="n">idx_mask</span> <span class="o">=</span> <span class="n">intervention_targets</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
                <span class="n">idx_mask_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx_mask</span><span class="p">)</span>
                <span class="n">intervention_targets</span><span class="p">[</span><span class="n">idx_mask</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># permute targets</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">):</span>
                <span class="n">intervention_targets</span><span class="p">[</span><span class="n">idx_mask_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">perm</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="n">dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">intervention_targets</span><span class="p">,</span> <span class="n">log_prob</span><span class="p">)</span>
        <span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.8</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
        <span class="n">val_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">train_size</span><span class="p">))</span>
        <span class="n">test_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">train_size</span> <span class="o">-</span> <span class="n">val_size</span>
        <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">val_dataset</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_dataset</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="n">train_size</span><span class="p">,</span> <span class="n">val_size</span><span class="p">,</span> <span class="n">test_size</span><span class="p">])</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">summary_stats</span> <span class="o">=</span> <span class="n">summary_statistics</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">intervention_targets</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">summary_stats</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">value</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">_summary_stats.csv&quot;</span><span class="p">)</span>
            <span class="n">plot_dag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">medgp</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">/</span> <span class="s2">&quot;base_coeff_values.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">medgp</span><span class="o">.</span><span class="n">latent_scm</span><span class="o">.</span><span class="n">base_coeff_values</span><span class="p">))</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="k">pass</span>
            <span class="c1"># save mixing function coefficients</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">medgp</span><span class="o">.</span><span class="n">mixing_function</span><span class="o">.</span><span class="n">save_coeffs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">num_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
        <span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">val_dataset</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">num_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">val_loader</span>

    <span class="k">def</span> <span class="nf">test_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
        <span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_dataset</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">num_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">test_loader</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">




<h2 id="data_generator.graph_sampler" class="doc doc-heading">
          <code>graph_sampler</code>


</h2>

  <div class="doc doc-contents ">

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">




<h3 id="data_generator.graph_sampler.sample_random_dag" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">sample_random_dag</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">edge_prob</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Sample a random DAG with n_nodes nodes and edge_prob probability of an edge between two nodes.</p>
<p>We ensure that there is at least one edge in the graph by rejecting graphs with no edges and
resampling.</p>
<h5 id="data_generator.graph_sampler.sample_random_dag--parameters">Parameters</h5>
<p>n_nodes: int
    Number of nodes in the graph.
edge_prob: float
    Probability of an edge between two nodes.</p>
<h5 id="data_generator.graph_sampler.sample_random_dag--returns">Returns</h5>
<p>adjaceny_matrix: np.ndarray, shape (n_nodes, n_nodes)
    The adjacency matrix of the sampled DAG.</p>

          <details class="quote">
            <summary>Source code in <code>data_generator/graph_sampler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sample_random_dag</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">edge_prob</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample a random DAG with n_nodes nodes and edge_prob probability of an edge between two nodes.</span>

<span class="sd">    We ensure that there is at least one edge in the graph by rejecting graphs with no edges and</span>
<span class="sd">    resampling.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_nodes: int</span>
<span class="sd">        Number of nodes in the graph.</span>
<span class="sd">    edge_prob: float</span>
<span class="sd">        Probability of an edge between two nodes.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    adjaceny_matrix: np.ndarray, shape (n_nodes, n_nodes)</span>
<span class="sd">        The adjacency matrix of the sampled DAG.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">adjaceny_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">edge_prob</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">))</span>
        <span class="c1"># put all lower triangular elements to zero</span>
        <span class="n">adjaceny_matrix</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">tril_indices</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># make sure the graph has at least one edge</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">adjaceny_matrix</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="n">adjaceny_matrix</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-module">




<h2 id="data_generator.mixing_function" class="doc doc-heading">
          <code>mixing_function</code>


</h2>

  <div class="doc doc-contents ">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">




<h3 id="data_generator.mixing_function.LinearMixing" class="doc doc-heading">
          <code>LinearMixing</code>


</h3>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="data_generator.mixing_function.MixingFunction" href="#data_generator.mixing_function.MixingFunction">MixingFunction</a></code></p>

  
      <p>Linear mixing function. The coefficients are sampled from a uniform distribution.</p>
<h5 id="data_generator.mixing_function.LinearMixing--parameters">Parameters</h5>
<p>latent_dim: int
    Dimension of the latent space.
observation_dim: int
    Dimension of the observation space.</p>

            <details class="quote">
              <summary>Source code in <code>data_generator/mixing_function.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">LinearMixing</span><span class="p">(</span><span class="n">MixingFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Linear mixing function. The coefficients are sampled from a uniform distribution.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    latent_dim: int</span>
<span class="sd">        Dimension of the latent space.</span>
<span class="sd">    observation_dim: int</span>
<span class="sd">        Dimension of the observation space.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">observation_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">observation_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coeffs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">observation_dim</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">coeffs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">save_coeffs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Path</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># save matrix coefficients</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">path</span> <span class="o">/</span> <span class="s2">&quot;matrix.pt&quot;</span><span class="p">)</span>
        <span class="n">matrix_np</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coeffs</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># convert to Numpy array</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">matrix_np</span><span class="p">)</span>  <span class="c1"># convert to a dataframe</span>
        <span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">path</span> <span class="o">/</span> <span class="s2">&quot;matrix.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># save as csv</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>

<div class="doc doc-object doc-class">




<h3 id="data_generator.mixing_function.MixingFunction" class="doc doc-heading">
          <code>MixingFunction</code>


</h3>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><span title="abc.ABC">ABC</span></code></p>

  
      <p>Base class for mixing functions.</p>
<p>The mixing function is the function that maps from the latent space to the observation space.</p>
<h5 id="data_generator.mixing_function.MixingFunction--parameters">Parameters</h5>
<p>latent_dim: int
    Dimension of the latent space.
observation_dim: int
    Dimension of the observation space.</p>

            <details class="quote">
              <summary>Source code in <code>data_generator/mixing_function.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MixingFunction</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for mixing functions.</span>

<span class="sd">    The mixing function is the function that maps from the latent space to the observation space.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    latent_dim: int</span>
<span class="sd">        Dimension of the latent space.</span>
<span class="sd">    observation_dim: int</span>
<span class="sd">        Dimension of the observation space.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">observation_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">latent_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_dim</span> <span class="o">=</span> <span class="n">observation_dim</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Apply the mixing function to the latent variables.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        v: Tensor, shape (num_samples, latent_dim)</span>
<span class="sd">            Latent variables.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        x: Tensor, shape (num_samples, observation_dim)</span>
<span class="sd">            Observed variables.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">save_coeffs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Path</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save the coefficients of the mixing function to disk.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        path: Path</span>
<span class="sd">            Path to save the coefficients to.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">unmixing_jacobian</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the jacobian of the inverse mixing function using autograd and the inverse function theorem.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        v: Tensor, shape (num_samples, latent_dim)</span>
<span class="sd">            Latent variables.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        unmixing_jacobian: Tensor, shape (num_samples, observation_dim, latent_dim)</span>
<span class="sd">            Jacobian of the inverse mixing function.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        https://en.wikipedia.org/wiki/Inverse_function_theorem</span>
<span class="sd">        https://discuss.pytorch.org/t/computing-batch-jacobian-efficiently/80771/7</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__call__</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">v</span>

        <span class="n">mixing_jacobian</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">func</span><span class="o">.</span><span class="n">jacrev</span><span class="p">(</span><span class="n">func</span><span class="p">))(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">unmixing_jacobian</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">mixing_jacobian</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">unmixing_jacobian</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">




<h4 id="data_generator.mixing_function.MixingFunction.__call__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__call__</span><span class="p">(</span><span class="n">v</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Apply the mixing function to the latent variables.</p>
<h6 id="data_generator.mixing_function.MixingFunction.__call__--parameters">Parameters</h6>
<p>v: Tensor, shape (num_samples, latent_dim)
    Latent variables.</p>
<h6 id="data_generator.mixing_function.MixingFunction.__call__--returns">Returns</h6>
<p>x: Tensor, shape (num_samples, observation_dim)
    Observed variables.</p>

          <details class="quote">
            <summary>Source code in <code>data_generator/mixing_function.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply the mixing function to the latent variables.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    v: Tensor, shape (num_samples, latent_dim)</span>
<span class="sd">        Latent variables.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    x: Tensor, shape (num_samples, observation_dim)</span>
<span class="sd">        Observed variables.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h4 id="data_generator.mixing_function.MixingFunction.save_coeffs" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">save_coeffs</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Save the coefficients of the mixing function to disk.</p>
<h6 id="data_generator.mixing_function.MixingFunction.save_coeffs--parameters">Parameters</h6>
<p>path: Path
    Path to save the coefficients to.</p>

          <details class="quote">
            <summary>Source code in <code>data_generator/mixing_function.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save_coeffs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Path</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Save the coefficients of the mixing function to disk.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    path: Path</span>
<span class="sd">        Path to save the coefficients to.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h4 id="data_generator.mixing_function.MixingFunction.unmixing_jacobian" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">unmixing_jacobian</span><span class="p">(</span><span class="n">v</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Compute the jacobian of the inverse mixing function using autograd and the inverse function theorem.</p>
<h6 id="data_generator.mixing_function.MixingFunction.unmixing_jacobian--parameters">Parameters</h6>
<p>v: Tensor, shape (num_samples, latent_dim)
    Latent variables.</p>
<h6 id="data_generator.mixing_function.MixingFunction.unmixing_jacobian--returns">Returns</h6>
<p>unmixing_jacobian: Tensor, shape (num_samples, observation_dim, latent_dim)
    Jacobian of the inverse mixing function.</p>
<h6 id="data_generator.mixing_function.MixingFunction.unmixing_jacobian--references">References</h6>
<p>https://en.wikipedia.org/wiki/Inverse_function_theorem
https://discuss.pytorch.org/t/computing-batch-jacobian-efficiently/80771/7</p>

          <details class="quote">
            <summary>Source code in <code>data_generator/mixing_function.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">unmixing_jacobian</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the jacobian of the inverse mixing function using autograd and the inverse function theorem.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    v: Tensor, shape (num_samples, latent_dim)</span>
<span class="sd">        Latent variables.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    unmixing_jacobian: Tensor, shape (num_samples, observation_dim, latent_dim)</span>
<span class="sd">        Jacobian of the inverse mixing function.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    https://en.wikipedia.org/wiki/Inverse_function_theorem</span>
<span class="sd">    https://discuss.pytorch.org/t/computing-batch-jacobian-efficiently/80771/7</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__call__</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">v</span>

    <span class="n">mixing_jacobian</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">func</span><span class="o">.</span><span class="n">jacrev</span><span class="p">(</span><span class="n">func</span><span class="p">))(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">unmixing_jacobian</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">mixing_jacobian</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">unmixing_jacobian</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">




<h3 id="data_generator.mixing_function.NonlinearMixing" class="doc doc-heading">
          <code>NonlinearMixing</code>


</h3>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="data_generator.mixing_function.MixingFunction" href="#data_generator.mixing_function.MixingFunction">MixingFunction</a></code></p>

  
      <p>Nonlinear mixing function.</p>
<p>The function is composed of a number of invertible matrices and leaky-tanh nonlinearities. I.e. we
apply a random neural network to the latent variables.</p>
<h5 id="data_generator.mixing_function.NonlinearMixing--parameters">Parameters</h5>
<p>latent_dim: int
    Dimension of the latent space.
observation_dim: int
    Dimension of the observation space.
n_nonlinearities: int
    Number of layers (i.e. invertible maps and nonlinearities) in the mixing function. Default: 1.</p>

            <details class="quote">
              <summary>Source code in <code>data_generator/mixing_function.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">NonlinearMixing</span><span class="p">(</span><span class="n">MixingFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Nonlinear mixing function.</span>

<span class="sd">    The function is composed of a number of invertible matrices and leaky-tanh nonlinearities. I.e. we</span>
<span class="sd">    apply a random neural network to the latent variables.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    latent_dim: int</span>
<span class="sd">        Dimension of the latent space.</span>
<span class="sd">    observation_dim: int</span>
<span class="sd">        Dimension of the observation space.</span>
<span class="sd">    n_nonlinearities: int</span>
<span class="sd">        Number of layers (i.e. invertible maps and nonlinearities) in the mixing function. Default: 1.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">observation_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_nonlinearities</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">observation_dim</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">latent_dim</span> <span class="o">==</span> <span class="n">observation_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coefs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">observation_dim</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_nonlinearities</span> <span class="o">=</span> <span class="n">n_nonlinearities</span>

        <span class="n">matrices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nonlinearities</span><span class="p">):</span>
            <span class="n">matrices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample_invertible_matrix</span><span class="p">(</span><span class="n">observation_dim</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">matrices</span> <span class="o">=</span> <span class="n">matrices</span>

        <span class="n">nonlinearities</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nonlinearities</span><span class="p">):</span>
            <span class="n">nonlinearities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">leaky_tanh</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nonlinearities</span> <span class="o">=</span> <span class="n">nonlinearities</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">v</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_nonlinearities</span><span class="p">):</span>
            <span class="n">mat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matrices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">nonlinearity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonlinearities</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">nonlinearity</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mat</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">save_coeffs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Path</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># save matrix coefficients</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_nonlinearities</span><span class="p">):</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">matrices</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">path</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;matrix_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">.pt&quot;</span><span class="p">)</span>
            <span class="n">matrix_np</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matrices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># convert to Numpy array</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">matrix_np</span><span class="p">)</span>  <span class="c1"># convert to a dataframe</span>
            <span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">path</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;matrix_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># save as csv</span>

        <span class="c1"># save matrix determinants in one csv</span>
        <span class="n">matrix_determinants</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_nonlinearities</span><span class="p">):</span>
            <span class="n">matrix_determinants</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">matrices</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
        <span class="n">matrix_determinants_np</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">matrix_determinants</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">matrix_determinants_np</span><span class="p">)</span>
        <span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">path</span> <span class="o">/</span> <span class="s2">&quot;matrix_determinants.csv&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">




<h2 id="data_generator.multi_env_gdp" class="doc doc-heading">
          <code>multi_env_gdp</code>


</h2>

  <div class="doc doc-contents ">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">




<h3 id="data_generator.multi_env_gdp.MultiEnvDGP" class="doc doc-heading">
          <code>MultiEnvDGP</code>


</h3>


  <div class="doc doc-contents ">

  
      <p>Multi-environment data generating process (DGP).</p>
<p>The DGP is defined by a latent structural causal model (SCM), a noise generator and a mixing function.
This class is used to generate data from those three components.</p>
<p>The latent SCM is a multi-environment SCM, i.e. it generates data for multiple environments which
differ by interventions on some of the variables. The noise generator is also multi-environmental,
i.e. it generates noise for multiple environments. The mixing function is a function that maps the
latent variables to the observed variables. The mixing function is the same for all environments.</p>
<h5 id="data_generator.multi_env_gdp.MultiEnvDGP--attributes">Attributes</h5>
<p>mixing_function: MixingFunction
    Mixing function.
latent_scm: MultiEnvLatentSCM
    Multi-environment latent SCM.
noise_generator: MultiEnvNoise
    Multi-environment noise generator.</p>
<h5 id="data_generator.multi_env_gdp.MultiEnvDGP--methods">Methods</h5>
<p>sample(num_samples_per_env, intervention_targets_per_env) -&gt; tuple[Tensor, ...]
    Sample from the DGP.</p>

            <details class="quote">
              <summary>Source code in <code>data_generator/multi_env_gdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 11</span>
<span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MultiEnvDGP</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Multi-environment data generating process (DGP).</span>

<span class="sd">    The DGP is defined by a latent structural causal model (SCM), a noise generator and a mixing function.</span>
<span class="sd">    This class is used to generate data from those three components.</span>

<span class="sd">    The latent SCM is a multi-environment SCM, i.e. it generates data for multiple environments which</span>
<span class="sd">    differ by interventions on some of the variables. The noise generator is also multi-environmental,</span>
<span class="sd">    i.e. it generates noise for multiple environments. The mixing function is a function that maps the</span>
<span class="sd">    latent variables to the observed variables. The mixing function is the same for all environments.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    mixing_function: MixingFunction</span>
<span class="sd">        Mixing function.</span>
<span class="sd">    latent_scm: MultiEnvLatentSCM</span>
<span class="sd">        Multi-environment latent SCM.</span>
<span class="sd">    noise_generator: MultiEnvNoise</span>
<span class="sd">        Multi-environment noise generator.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    sample(num_samples_per_env, intervention_targets_per_env) -&gt; tuple[Tensor, ...]</span>
<span class="sd">        Sample from the DGP.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">mixing_function</span><span class="p">:</span> <span class="n">MixingFunction</span><span class="p">,</span>
        <span class="n">latent_scm</span><span class="p">:</span> <span class="n">MultiEnvLatentSCM</span><span class="p">,</span>
        <span class="n">noise_generator</span><span class="p">:</span> <span class="n">MultiEnvNoise</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mixing_function</span> <span class="o">=</span> <span class="n">mixing_function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_scm</span> <span class="o">=</span> <span class="n">latent_scm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_generator</span> <span class="o">=</span> <span class="n">noise_generator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adjacency_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent_scm</span><span class="o">.</span><span class="n">adjacency_matrix</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_samples_per_env</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sample from the DGP.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        num_samples_per_env: int</span>
<span class="sd">            Number of samples to generate per environment.</span>
<span class="sd">        intervention_targets_per_env: Tensor, shape (num_envs, num_causal_variables)</span>
<span class="sd">            Intervention targets per environment, with 1 indicating that the variable is intervened on</span>
<span class="sd">            and 0 indicating that the variable is not intervened on. This variable also implicitly defines</span>
<span class="sd">            the number of environments.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        x: Tensor, shape (num_samples_per_env * num_envs, observation_dim)</span>
<span class="sd">            Samples of observed variables.</span>
<span class="sd">        v: Tensor, shape (num_samples_per_env * num_envs, latent_dim)</span>
<span class="sd">            Samples of latent variables.</span>
<span class="sd">        u: Tensor, shape (num_samples_per_env * num_envs, latent_dim)</span>
<span class="sd">            Samples of exogenous noise variables.</span>
<span class="sd">        e: Tensor, shape (num_samples_per_env * num_envs, 1)</span>
<span class="sd">            Environment indicator.</span>
<span class="sd">        intervention_targets: Tensor, shape (num_samples_per_env * num_envs, latent_dim)</span>
<span class="sd">            Intervention targets.</span>
<span class="sd">        log_prob: Tensor, shape (num_samples_per_env * num_envs, 1)</span>
<span class="sd">            Ground-truth log probability of the samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">num_envs</span> <span class="o">=</span> <span class="n">intervention_targets_per_env</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">num_samples_per_env</span><span class="p">,</span>
            <span class="n">num_envs</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">latent_scm</span><span class="o">.</span><span class="n">latent_dim</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">intervention_targets_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">e</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_samples_per_env</span><span class="p">,</span> <span class="n">num_envs</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_samples_per_env</span><span class="p">,</span> <span class="n">num_envs</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">env</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_envs</span><span class="p">):</span>
            <span class="n">int_targets_env</span> <span class="o">=</span> <span class="n">intervention_targets_per_env</span><span class="p">[</span><span class="n">env</span><span class="p">,</span> <span class="p">:]</span>

            <span class="n">noise_samples_env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_generator</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
                <span class="n">env</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">num_samples_per_env</span>
            <span class="p">)</span>
            <span class="n">noise_log_prob_env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_generator</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">noise_samples_env</span><span class="p">,</span> <span class="n">env</span><span class="p">)</span>

            <span class="n">latent_samples_env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent_scm</span><span class="o">.</span><span class="n">push_forward</span><span class="p">(</span><span class="n">noise_samples_env</span><span class="p">,</span> <span class="n">env</span><span class="p">)</span>
            <span class="n">log_det_scm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent_scm</span><span class="o">.</span><span class="n">log_inverse_jacobian</span><span class="p">(</span>
                <span class="n">latent_samples_env</span><span class="p">,</span> <span class="n">noise_samples_env</span><span class="p">,</span> <span class="n">env</span>
            <span class="p">)</span>

            <span class="n">intervention_targets_out</span><span class="p">[:,</span> <span class="n">env</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">int_targets_env</span>
            <span class="n">u</span><span class="p">[:,</span> <span class="n">env</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">noise_samples_env</span>
            <span class="n">v</span><span class="p">[:,</span> <span class="n">env</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">latent_samples_env</span>
            <span class="n">e</span><span class="p">[:,</span> <span class="n">env</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">env</span>
            <span class="n">log_prob</span><span class="p">[:,</span> <span class="n">env</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">log_det_scm</span> <span class="o">+</span> <span class="n">noise_log_prob_env</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">flattened_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_samples_per_env</span> <span class="o">*</span> <span class="n">num_envs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent_scm</span><span class="o">.</span><span class="n">latent_dim</span><span class="p">)</span>
        <span class="n">intervention_targets_out</span> <span class="o">=</span> <span class="n">intervention_targets_out</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">flattened_shape</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">flattened_shape</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">flattened_shape</span><span class="p">)</span>
        <span class="n">e</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">num_samples_per_env</span> <span class="o">*</span> <span class="n">num_envs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="n">log_prob</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">num_samples_per_env</span> <span class="o">*</span> <span class="n">num_envs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mixing_function</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="n">unmixing_jacobian</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mixing_function</span><span class="o">.</span><span class="n">unmixing_jacobian</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="n">log_det_unmixing_jacobian</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">slogdet</span><span class="p">(</span>
            <span class="n">unmixing_jacobian</span>
        <span class="p">)</span><span class="o">.</span><span class="n">logabsdet</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">log_prob</span> <span class="o">+=</span> <span class="n">log_det_unmixing_jacobian</span>

        <span class="k">return</span> <span class="p">(</span>
            <span class="n">x</span><span class="p">,</span>
            <span class="n">v</span><span class="p">,</span>
            <span class="n">u</span><span class="p">,</span>
            <span class="n">e</span><span class="p">,</span>
            <span class="n">intervention_targets_out</span><span class="p">,</span>
            <span class="n">log_prob</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">




<h4 id="data_generator.multi_env_gdp.MultiEnvDGP.sample" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">sample</span><span class="p">(</span><span class="n">num_samples_per_env</span><span class="p">,</span> <span class="n">intervention_targets_per_env</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Sample from the DGP.</p>
<h6 id="data_generator.multi_env_gdp.MultiEnvDGP.sample--parameters">Parameters</h6>
<p>num_samples_per_env: int
    Number of samples to generate per environment.
intervention_targets_per_env: Tensor, shape (num_envs, num_causal_variables)
    Intervention targets per environment, with 1 indicating that the variable is intervened on
    and 0 indicating that the variable is not intervened on. This variable also implicitly defines
    the number of environments.</p>
<h6 id="data_generator.multi_env_gdp.MultiEnvDGP.sample--returns">Returns</h6>
<p>x: Tensor, shape (num_samples_per_env * num_envs, observation_dim)
    Samples of observed variables.
v: Tensor, shape (num_samples_per_env * num_envs, latent_dim)
    Samples of latent variables.
u: Tensor, shape (num_samples_per_env * num_envs, latent_dim)
    Samples of exogenous noise variables.
e: Tensor, shape (num_samples_per_env * num_envs, 1)
    Environment indicator.
intervention_targets: Tensor, shape (num_samples_per_env * num_envs, latent_dim)
    Intervention targets.
log_prob: Tensor, shape (num_samples_per_env * num_envs, 1)
    Ground-truth log probability of the samples.</p>

          <details class="quote">
            <summary>Source code in <code>data_generator/multi_env_gdp.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">num_samples_per_env</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample from the DGP.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    num_samples_per_env: int</span>
<span class="sd">        Number of samples to generate per environment.</span>
<span class="sd">    intervention_targets_per_env: Tensor, shape (num_envs, num_causal_variables)</span>
<span class="sd">        Intervention targets per environment, with 1 indicating that the variable is intervened on</span>
<span class="sd">        and 0 indicating that the variable is not intervened on. This variable also implicitly defines</span>
<span class="sd">        the number of environments.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    x: Tensor, shape (num_samples_per_env * num_envs, observation_dim)</span>
<span class="sd">        Samples of observed variables.</span>
<span class="sd">    v: Tensor, shape (num_samples_per_env * num_envs, latent_dim)</span>
<span class="sd">        Samples of latent variables.</span>
<span class="sd">    u: Tensor, shape (num_samples_per_env * num_envs, latent_dim)</span>
<span class="sd">        Samples of exogenous noise variables.</span>
<span class="sd">    e: Tensor, shape (num_samples_per_env * num_envs, 1)</span>
<span class="sd">        Environment indicator.</span>
<span class="sd">    intervention_targets: Tensor, shape (num_samples_per_env * num_envs, latent_dim)</span>
<span class="sd">        Intervention targets.</span>
<span class="sd">    log_prob: Tensor, shape (num_samples_per_env * num_envs, 1)</span>
<span class="sd">        Ground-truth log probability of the samples.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">num_envs</span> <span class="o">=</span> <span class="n">intervention_targets_per_env</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">num_samples_per_env</span><span class="p">,</span>
        <span class="n">num_envs</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_scm</span><span class="o">.</span><span class="n">latent_dim</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">intervention_targets_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_samples_per_env</span><span class="p">,</span> <span class="n">num_envs</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
    <span class="n">log_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_samples_per_env</span><span class="p">,</span> <span class="n">num_envs</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">env</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_envs</span><span class="p">):</span>
        <span class="n">int_targets_env</span> <span class="o">=</span> <span class="n">intervention_targets_per_env</span><span class="p">[</span><span class="n">env</span><span class="p">,</span> <span class="p">:]</span>

        <span class="n">noise_samples_env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_generator</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
            <span class="n">env</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">num_samples_per_env</span>
        <span class="p">)</span>
        <span class="n">noise_log_prob_env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_generator</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">noise_samples_env</span><span class="p">,</span> <span class="n">env</span><span class="p">)</span>

        <span class="n">latent_samples_env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent_scm</span><span class="o">.</span><span class="n">push_forward</span><span class="p">(</span><span class="n">noise_samples_env</span><span class="p">,</span> <span class="n">env</span><span class="p">)</span>
        <span class="n">log_det_scm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent_scm</span><span class="o">.</span><span class="n">log_inverse_jacobian</span><span class="p">(</span>
            <span class="n">latent_samples_env</span><span class="p">,</span> <span class="n">noise_samples_env</span><span class="p">,</span> <span class="n">env</span>
        <span class="p">)</span>

        <span class="n">intervention_targets_out</span><span class="p">[:,</span> <span class="n">env</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">int_targets_env</span>
        <span class="n">u</span><span class="p">[:,</span> <span class="n">env</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">noise_samples_env</span>
        <span class="n">v</span><span class="p">[:,</span> <span class="n">env</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">latent_samples_env</span>
        <span class="n">e</span><span class="p">[:,</span> <span class="n">env</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">env</span>
        <span class="n">log_prob</span><span class="p">[:,</span> <span class="n">env</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">log_det_scm</span> <span class="o">+</span> <span class="n">noise_log_prob_env</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">flattened_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_samples_per_env</span> <span class="o">*</span> <span class="n">num_envs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent_scm</span><span class="o">.</span><span class="n">latent_dim</span><span class="p">)</span>
    <span class="n">intervention_targets_out</span> <span class="o">=</span> <span class="n">intervention_targets_out</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">flattened_shape</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">flattened_shape</span><span class="p">)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">flattened_shape</span><span class="p">)</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">num_samples_per_env</span> <span class="o">*</span> <span class="n">num_envs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">log_prob</span> <span class="o">=</span> <span class="n">log_prob</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">num_samples_per_env</span> <span class="o">*</span> <span class="n">num_envs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mixing_function</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="n">unmixing_jacobian</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mixing_function</span><span class="o">.</span><span class="n">unmixing_jacobian</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="n">log_det_unmixing_jacobian</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">slogdet</span><span class="p">(</span>
        <span class="n">unmixing_jacobian</span>
    <span class="p">)</span><span class="o">.</span><span class="n">logabsdet</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">log_prob</span> <span class="o">+=</span> <span class="n">log_det_unmixing_jacobian</span>

    <span class="k">return</span> <span class="p">(</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">v</span><span class="p">,</span>
        <span class="n">u</span><span class="p">,</span>
        <span class="n">e</span><span class="p">,</span>
        <span class="n">intervention_targets_out</span><span class="p">,</span>
        <span class="n">log_prob</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>



<div class="doc doc-object doc-function">




<h3 id="data_generator.multi_env_gdp.make_multi_env_dgp" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">make_multi_env_dgp</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">observation_dim</span><span class="p">,</span> <span class="n">adjacency_matrix</span><span class="p">,</span> <span class="n">intervention_targets_per_env</span><span class="p">,</span> <span class="n">shift_noise</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">noise_shift_type</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">mixing</span><span class="o">=</span><span class="s1">&#39;nonlinear&#39;</span><span class="p">,</span> <span class="n">scm</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">n_nonlinearities</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scm_coeffs_low</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">scm_coeffs_high</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">coeffs_min_abs_value</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">edge_prob</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">snr</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Create a multi-environment data generating process (DGP).</p>
<h5 id="data_generator.multi_env_gdp.make_multi_env_dgp--parameters">Parameters</h5>
<p>latent_dim: int
    Dimension of the latent variables.
observation_dim: int
    Dimension of the observed variables.
adjacency_matrix: np.ndarray, shape (latent_dim, latent_dim)
    Adjacency matrix of the latent SCM.
intervention_targets_per_env: Tensor, shape (num_envs, latent_dim)
    Intervention targets per environment, with 1 indicating that the variable is intervened on
    and 0 indicating that the variable is not intervened on. This variable also implicitly defines
    the number of environments.
shift_noise: bool
    Whether to shift the noise distribution for variables that are intervened on. Default: False.
noise_shift_type: str
    Whether to shift the mean or standard deviation of the noise distribution for variables that are intervened on.
    Options: "mean" or "std". Default: "mean".
mixing: str
    Mixing function. Options: "linear" or "nonlinear". Default: "nonlinear".
scm: str
    Latent SCM. Options: "linear" or "location-scale". Default: "linear".
n_nonlinearities: int
    Number of nonlinearities in the nonlinear mixing function. Default: 1.
scm_coeffs_low: float
    Lower bound of the SCM coefficients in linear SCMs. Default: -1.
scm_coeffs_high: float
    Upper bound of the SCM coefficients in linear SCMs. Default: 1.
coeffs_min_abs_value: float
    Minimum absolute value of the SCM coefficients in linear SCMs. If None, no minimum absolute value is enforced.
    Default: None.
edge_prob: float
    Probability of an edge in the adjacency matrix if no adjacency matrix is given. Default: None.
snr: float
    Signal-to-noise ratio of the location-scale SCM. Default: 1.0.</p>
<h5 id="data_generator.multi_env_gdp.make_multi_env_dgp--returns">Returns</h5>
<p>medgp: MultiEnvDGP
    Multi-environment data generating process.</p>

          <details class="quote">
            <summary>Source code in <code>data_generator/multi_env_gdp.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">make_multi_env_dgp</span><span class="p">(</span>
    <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">observation_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">adjacency_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">shift_noise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">noise_shift_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
    <span class="n">mixing</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;nonlinear&quot;</span><span class="p">,</span>
    <span class="n">scm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;linear&quot;</span><span class="p">,</span>
    <span class="n">n_nonlinearities</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">scm_coeffs_low</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">scm_coeffs_high</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">coeffs_min_abs_value</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">snr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MultiEnvDGP</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a multi-environment data generating process (DGP).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    latent_dim: int</span>
<span class="sd">        Dimension of the latent variables.</span>
<span class="sd">    observation_dim: int</span>
<span class="sd">        Dimension of the observed variables.</span>
<span class="sd">    adjacency_matrix: np.ndarray, shape (latent_dim, latent_dim)</span>
<span class="sd">        Adjacency matrix of the latent SCM.</span>
<span class="sd">    intervention_targets_per_env: Tensor, shape (num_envs, latent_dim)</span>
<span class="sd">        Intervention targets per environment, with 1 indicating that the variable is intervened on</span>
<span class="sd">        and 0 indicating that the variable is not intervened on. This variable also implicitly defines</span>
<span class="sd">        the number of environments.</span>
<span class="sd">    shift_noise: bool</span>
<span class="sd">        Whether to shift the noise distribution for variables that are intervened on. Default: False.</span>
<span class="sd">    noise_shift_type: str</span>
<span class="sd">        Whether to shift the mean or standard deviation of the noise distribution for variables that are intervened on.</span>
<span class="sd">        Options: &quot;mean&quot; or &quot;std&quot;. Default: &quot;mean&quot;.</span>
<span class="sd">    mixing: str</span>
<span class="sd">        Mixing function. Options: &quot;linear&quot; or &quot;nonlinear&quot;. Default: &quot;nonlinear&quot;.</span>
<span class="sd">    scm: str</span>
<span class="sd">        Latent SCM. Options: &quot;linear&quot; or &quot;location-scale&quot;. Default: &quot;linear&quot;.</span>
<span class="sd">    n_nonlinearities: int</span>
<span class="sd">        Number of nonlinearities in the nonlinear mixing function. Default: 1.</span>
<span class="sd">    scm_coeffs_low: float</span>
<span class="sd">        Lower bound of the SCM coefficients in linear SCMs. Default: -1.</span>
<span class="sd">    scm_coeffs_high: float</span>
<span class="sd">        Upper bound of the SCM coefficients in linear SCMs. Default: 1.</span>
<span class="sd">    coeffs_min_abs_value: float</span>
<span class="sd">        Minimum absolute value of the SCM coefficients in linear SCMs. If None, no minimum absolute value is enforced.</span>
<span class="sd">        Default: None.</span>
<span class="sd">    edge_prob: float</span>
<span class="sd">        Probability of an edge in the adjacency matrix if no adjacency matrix is given. Default: None.</span>
<span class="sd">    snr: float</span>
<span class="sd">        Signal-to-noise ratio of the location-scale SCM. Default: 1.0.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    medgp: MultiEnvDGP</span>
<span class="sd">        Multi-environment data generating process.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">mixing</span> <span class="o">==</span> <span class="s2">&quot;linear&quot;</span><span class="p">:</span>
        <span class="n">mixing_function</span> <span class="o">=</span> <span class="n">LinearMixing</span><span class="p">(</span>
            <span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">observation_dim</span><span class="o">=</span><span class="n">observation_dim</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">mixing</span> <span class="o">==</span> <span class="s2">&quot;nonlinear&quot;</span><span class="p">:</span>
        <span class="n">mixing_function</span> <span class="o">=</span> <span class="n">NonlinearMixing</span><span class="p">(</span>
            <span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span>
            <span class="n">observation_dim</span><span class="o">=</span><span class="n">observation_dim</span><span class="p">,</span>
            <span class="n">n_nonlinearities</span><span class="o">=</span><span class="n">n_nonlinearities</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown mixing function </span><span class="si">{</span><span class="n">mixing</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># if adjacency_matrix is not given as numpy array, sample a random one</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">adjacency_matrix</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">edge_prob</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">),</span> <span class="s2">&quot;edge_prob must be given if no adjacency_matrix is given&quot;</span>
        <span class="n">adjacency_matrix</span> <span class="o">=</span> <span class="n">sample_random_dag</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">edge_prob</span><span class="p">)</span>
    <span class="n">adjacency_matrix</span> <span class="o">=</span> <span class="n">adjacency_matrix</span>

    <span class="k">if</span> <span class="n">scm</span> <span class="o">==</span> <span class="s2">&quot;linear&quot;</span><span class="p">:</span>
        <span class="n">latent_scm</span> <span class="o">=</span> <span class="n">LinearSCM</span><span class="p">(</span>
            <span class="n">adjacency_matrix</span><span class="o">=</span><span class="n">adjacency_matrix</span><span class="p">,</span>
            <span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span>
            <span class="n">intervention_targets_per_env</span><span class="o">=</span><span class="n">intervention_targets_per_env</span><span class="p">,</span>
            <span class="n">coeffs_low</span><span class="o">=</span><span class="n">scm_coeffs_low</span><span class="p">,</span>
            <span class="n">coeffs_high</span><span class="o">=</span><span class="n">scm_coeffs_high</span><span class="p">,</span>
            <span class="n">coeffs_min_abs_value</span><span class="o">=</span><span class="n">coeffs_min_abs_value</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">scm</span> <span class="o">==</span> <span class="s2">&quot;location-scale&quot;</span><span class="p">:</span>
        <span class="n">latent_scm</span> <span class="o">=</span> <span class="n">LocationScaleSCM</span><span class="p">(</span>
            <span class="n">adjacency_matrix</span><span class="o">=</span><span class="n">adjacency_matrix</span><span class="p">,</span>
            <span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span>
            <span class="n">intervention_targets_per_env</span><span class="o">=</span><span class="n">intervention_targets_per_env</span><span class="p">,</span>
            <span class="n">snr</span><span class="o">=</span><span class="n">snr</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown SCM </span><span class="si">{</span><span class="n">scm</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">noise_generator</span> <span class="o">=</span> <span class="n">GaussianNoise</span><span class="p">(</span>
        <span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span>
        <span class="n">intervention_targets_per_env</span><span class="o">=</span><span class="n">intervention_targets_per_env</span><span class="p">,</span>
        <span class="n">shift</span><span class="o">=</span><span class="n">shift_noise</span><span class="p">,</span>
        <span class="n">shift_type</span><span class="o">=</span><span class="n">noise_shift_type</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">medgp</span> <span class="o">=</span> <span class="n">MultiEnvDGP</span><span class="p">(</span>
        <span class="n">latent_scm</span><span class="o">=</span><span class="n">latent_scm</span><span class="p">,</span>
        <span class="n">noise_generator</span><span class="o">=</span><span class="n">noise_generator</span><span class="p">,</span>
        <span class="n">mixing_function</span><span class="o">=</span><span class="n">mixing_function</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">medgp</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-module">




<h2 id="data_generator.noise_generator" class="doc doc-heading">
          <code>noise_generator</code>


</h2>

  <div class="doc doc-contents ">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">




<h3 id="data_generator.noise_generator.MultiEnvNoise" class="doc doc-heading">
          <code>MultiEnvNoise</code>


</h3>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><span title="abc.ABC">ABC</span></code></p>

  
      <p>Base class for multi-environment noise generators.</p>
<h5 id="data_generator.noise_generator.MultiEnvNoise--attributes">Attributes</h5>
<p>latent_dim: int
    Latent dimension.
intervention_targets_per_env: Tensor, shape (num_envs, latent_dim)
    Intervention targets per environment, with 1 indicating that the variable is intervened on
    and 0 indicating that the variable is not intervened on. This variable also implicitly defines
    the number of environments.
mean: float
    Mean of the noise distribution. If shift is True and shift_type is "mean", the mean of the noise
    distribution is shifted up or down depending on whether the mechanism is intervened on or not. Default: 0.0.
std: float
    Standard deviation of the noise distribution. If shift is True and shift_type is "std", the standard
    deviation of the noise distribution is shifted up or down depending on whether the mechanism is intervened
    on or not. Default: 1.0.
shift: bool
    Whether to shift the noise distribution for variables that are intervened on. Default: False.
shift_type: str
    Whether to shift the mean or standard deviation of the noise distribution for variables that are intervened on.
    Options: "mean" or "std". Default: "mean".</p>
<h5 id="data_generator.noise_generator.MultiEnvNoise--methods">Methods</h5>
<p>sample(e, size=1) -&gt; Tensor
    Sample from the noise distribution for a given environment.</p>

            <details class="quote">
              <summary>Source code in <code>data_generator/noise_generator.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MultiEnvNoise</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for multi-environment noise generators.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    latent_dim: int</span>
<span class="sd">        Latent dimension.</span>
<span class="sd">    intervention_targets_per_env: Tensor, shape (num_envs, latent_dim)</span>
<span class="sd">        Intervention targets per environment, with 1 indicating that the variable is intervened on</span>
<span class="sd">        and 0 indicating that the variable is not intervened on. This variable also implicitly defines</span>
<span class="sd">        the number of environments.</span>
<span class="sd">    mean: float</span>
<span class="sd">        Mean of the noise distribution. If shift is True and shift_type is &quot;mean&quot;, the mean of the noise</span>
<span class="sd">        distribution is shifted up or down depending on whether the mechanism is intervened on or not. Default: 0.0.</span>
<span class="sd">    std: float</span>
<span class="sd">        Standard deviation of the noise distribution. If shift is True and shift_type is &quot;std&quot;, the standard</span>
<span class="sd">        deviation of the noise distribution is shifted up or down depending on whether the mechanism is intervened</span>
<span class="sd">        on or not. Default: 1.0.</span>
<span class="sd">    shift: bool</span>
<span class="sd">        Whether to shift the noise distribution for variables that are intervened on. Default: False.</span>
<span class="sd">    shift_type: str</span>
<span class="sd">        Whether to shift the mean or standard deviation of the noise distribution for variables that are intervened on.</span>
<span class="sd">        Options: &quot;mean&quot; or &quot;std&quot;. Default: &quot;mean&quot;.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    sample(e, size=1) -&gt; Tensor</span>
<span class="sd">        Sample from the noise distribution for a given environment.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">shift</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">shift_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">latent_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intervention_targets</span> <span class="o">=</span> <span class="n">intervention_targets_per_env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shift</span> <span class="o">=</span> <span class="n">shift</span>
        <span class="k">assert</span> <span class="n">shift_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">],</span> <span class="sa">f</span><span class="s2">&quot;Invalid shift type: </span><span class="si">{</span><span class="n">shift_type</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shift_type</span> <span class="o">=</span> <span class="n">shift_type</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sample from the noise distribution for a given environment.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        e: int</span>
<span class="sd">            Environment index. Must be in {0, ..., num_envs-1}. The number of environments is implicitly defined</span>
<span class="sd">            by the intervention_targets_per_env variable.</span>
<span class="sd">        size: int</span>
<span class="sd">            Number of samples to generate. Default: 1.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tensor, shape (size, latent_dim)</span>
<span class="sd">            Samples from the noise distribution.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the log probability of u under the noise distribution for a given environment. We assume</span>
<span class="sd">        that all samples come from the same environment.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        u: Tensor, shape (size, latent_dim)</span>
<span class="sd">            Samples from the noise distribution.</span>
<span class="sd">        e: int</span>
<span class="sd">            Environment index. Must be in {0, ..., num_envs-1}. The number of environments is implicitly defined</span>
<span class="sd">            by the intervention_targets_per_env variable.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        log_prob: Tensor, shape (size, latent_dim)</span>
<span class="sd">            Log probability of u.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">




<h4 id="data_generator.noise_generator.MultiEnvNoise.log_prob" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">log_prob</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Compute the log probability of u under the noise distribution for a given environment. We assume
that all samples come from the same environment.</p>
<h6 id="data_generator.noise_generator.MultiEnvNoise.log_prob--parameters">Parameters</h6>
<p>u: Tensor, shape (size, latent_dim)
    Samples from the noise distribution.
e: int
    Environment index. Must be in {0, ..., num_envs-1}. The number of environments is implicitly defined
    by the intervention_targets_per_env variable.</p>
<h6 id="data_generator.noise_generator.MultiEnvNoise.log_prob--returns">Returns</h6>
<p>log_prob: Tensor, shape (size, latent_dim)
    Log probability of u.</p>

          <details class="quote">
            <summary>Source code in <code>data_generator/noise_generator.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the log probability of u under the noise distribution for a given environment. We assume</span>
<span class="sd">    that all samples come from the same environment.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    u: Tensor, shape (size, latent_dim)</span>
<span class="sd">        Samples from the noise distribution.</span>
<span class="sd">    e: int</span>
<span class="sd">        Environment index. Must be in {0, ..., num_envs-1}. The number of environments is implicitly defined</span>
<span class="sd">        by the intervention_targets_per_env variable.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    log_prob: Tensor, shape (size, latent_dim)</span>
<span class="sd">        Log probability of u.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h4 id="data_generator.noise_generator.MultiEnvNoise.sample" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">sample</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Sample from the noise distribution for a given environment.</p>
<h6 id="data_generator.noise_generator.MultiEnvNoise.sample--parameters">Parameters</h6>
<p>e: int
    Environment index. Must be in {0, ..., num_envs-1}. The number of environments is implicitly defined
    by the intervention_targets_per_env variable.
size: int
    Number of samples to generate. Default: 1.</p>
<h6 id="data_generator.noise_generator.MultiEnvNoise.sample--returns">Returns</h6>
<p>Tensor, shape (size, latent_dim)
    Samples from the noise distribution.</p>

          <details class="quote">
            <summary>Source code in <code>data_generator/noise_generator.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample from the noise distribution for a given environment.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    e: int</span>
<span class="sd">        Environment index. Must be in {0, ..., num_envs-1}. The number of environments is implicitly defined</span>
<span class="sd">        by the intervention_targets_per_env variable.</span>
<span class="sd">    size: int</span>
<span class="sd">        Number of samples to generate. Default: 1.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Tensor, shape (size, latent_dim)</span>
<span class="sd">        Samples from the noise distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">




<h2 id="data_generator.scm" class="doc doc-heading">
          <code>scm</code>


</h2>

  <div class="doc doc-contents ">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">




<h3 id="data_generator.scm.LinearSCM" class="doc doc-heading">
          <code>LinearSCM</code>


</h3>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="data_generator.scm.MultiEnvLatentSCM" href="#data_generator.scm.MultiEnvLatentSCM">MultiEnvLatentSCM</a></code></p>

  
      <p>Multi-environment latent SCM, where all causal mechanisms are linear. The coefficients of the
linear causal mechanisms are sampled from a uniform distribution.</p>
<p>Inherits all attributes and methods from MultiEnvLatentSCM.</p>
<h5 id="data_generator.scm.LinearSCM--additional-attributes">Additional attributes</h5>
<p>coeffs_low : float
    Lower bound for the coefficients of the linear causal mechanisms. Default: -1.0.
coeffs_high : float
    Upper bound for the coefficients of the linear causal mechanisms. Default: 1.0.
coeffs_min_abs_value : Optional[float]
    Minimum absolute value for the coefficients of the linear causal mechanisms. If None, no
    minimum absolute value is enforced. Default: None.</p>
<h5 id="data_generator.scm.LinearSCM--additional-methods">Additional methods</h5>
<p>setup_functions_per_env(intervention_targets_per_env: Tensor) -&gt; tuple[dict[int, callable], dict[int, callable]]
    Set up the functions_per_env and inverse_jac_per_env attributes. This is where the linear
    causal mechanisms are defined.</p>

            <details class="quote">
              <summary>Source code in <code>data_generator/scm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">LinearSCM</span><span class="p">(</span><span class="n">MultiEnvLatentSCM</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Multi-environment latent SCM, where all causal mechanisms are linear. The coefficients of the</span>
<span class="sd">    linear causal mechanisms are sampled from a uniform distribution.</span>

<span class="sd">    Inherits all attributes and methods from MultiEnvLatentSCM.</span>

<span class="sd">    Additional attributes</span>
<span class="sd">    ---------------------</span>
<span class="sd">    coeffs_low : float</span>
<span class="sd">        Lower bound for the coefficients of the linear causal mechanisms. Default: -1.0.</span>
<span class="sd">    coeffs_high : float</span>
<span class="sd">        Upper bound for the coefficients of the linear causal mechanisms. Default: 1.0.</span>
<span class="sd">    coeffs_min_abs_value : Optional[float]</span>
<span class="sd">        Minimum absolute value for the coefficients of the linear causal mechanisms. If None, no</span>
<span class="sd">        minimum absolute value is enforced. Default: None.</span>

<span class="sd">    Additional methods</span>
<span class="sd">    ------------------</span>
<span class="sd">    setup_functions_per_env(intervention_targets_per_env: Tensor) -&gt; tuple[dict[int, callable], dict[int, callable]]</span>
<span class="sd">        Set up the functions_per_env and inverse_jac_per_env attributes. This is where the linear</span>
<span class="sd">        causal mechanisms are defined.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">adjacency_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">coeffs_low</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">coeffs_high</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">coeffs_min_abs_value</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        adjacency_matrix: np.ndarray, shape (latent_dim, latent_dim)</span>
<span class="sd">        latent_dim: int</span>
<span class="sd">        intervention_targets_per_env: Tensor, shape (num_envs, latent_dim)</span>
<span class="sd">        coeffs_low: float</span>
<span class="sd">        coeffs_high: float</span>
<span class="sd">        coeffs_min_abs_value: Optional[float]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">adjacency_matrix</span><span class="p">,</span>
            <span class="n">latent_dim</span><span class="p">,</span>
            <span class="n">intervention_targets_per_env</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_low</span> <span class="o">=</span> <span class="n">coeffs_low</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_high</span> <span class="o">=</span> <span class="n">coeffs_high</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_min_abs_value</span> <span class="o">=</span> <span class="n">coeffs_min_abs_value</span>

        <span class="n">base_functions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">base_inverse_jac</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">base_coeff_values</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span><span class="p">):</span>
            <span class="n">parents</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dag</span><span class="o">.</span><span class="n">predecessors</span><span class="p">(</span><span class="n">index</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span>
            <span class="p">)</span>
            <span class="n">coeffs</span> <span class="o">=</span> <span class="n">sample_coeffs</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_low</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_high</span><span class="p">,</span>
                <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,),</span>
                <span class="n">min_abs_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">coeffs_min_abs_value</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">coeffs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># set the noise coefficient to 1</span>

            <span class="n">base_functions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">partial</span><span class="p">(</span><span class="n">linear_base_func</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">,</span> <span class="n">coeffs</span><span class="o">=</span><span class="n">coeffs</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">base_inverse_jac</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">partial</span><span class="p">(</span>
                    <span class="n">linear_inverse_jacobian</span><span class="p">,</span>
                    <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">,</span>
                    <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">,</span>
                    <span class="n">coeffs</span><span class="o">=</span><span class="n">coeffs</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="n">base_coeff_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">coeffs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_functions</span> <span class="o">=</span> <span class="n">base_functions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_inverse_jac</span> <span class="o">=</span> <span class="n">base_inverse_jac</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_coeff_values</span> <span class="o">=</span> <span class="n">base_coeff_values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">functions_per_env</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inverse_jac_per_env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">setup_functions_per_env</span><span class="p">(</span>
            <span class="n">intervention_targets_per_env</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">setup_functions_per_env</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">callable</span><span class="p">],</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">callable</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set up the functions_per_env and inverse_jac_per_env attributes. This is where the linear</span>
<span class="sd">        causal mechanisms are defined.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        intervention_targets_per_env: Tensor, shape (num_envs, latent_dim)</span>
<span class="sd">            Intervention targets for each environment.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        functions_per_env: dict[int, dict[int, callable]]</span>
<span class="sd">            Dictionary mapping environment indices to dictionaries mapping latent variable indices to</span>
<span class="sd">            functions that implement the causal mechanism. I.e. functions_per_env[env][index] is a</span>
<span class="sd">            function that takes two arguments, v and u, and returns a Tensor of shape (batch_size,</span>
<span class="sd">            latent_dim) that contains the result of applying the causal mechanism the parents of index.</span>
<span class="sd">        inverse_jac_per_env: dict[int, dict[int, callable]]</span>
<span class="sd">            Dictionary mapping environment indices to dictionaries mapping latent variable indices to</span>
<span class="sd">            functions that implement the log of the inverse Jacobian of the causal mechanism. I.e.</span>
<span class="sd">            inverse_jac_per_env[env][index] is a function that takes two arguments, v and u, and</span>
<span class="sd">            returns a Tensor of shape (batch_size,) that contains the log of the inverse Jacobian of</span>
<span class="sd">            the causal mechanism applied to the parents of index.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">functions_per_env</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">inverse_jac_per_env</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">num_envs</span> <span class="o">=</span> <span class="n">intervention_targets_per_env</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">env</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_envs</span><span class="p">):</span>
            <span class="n">functions_env</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">inverse_jac_env</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">topological_order</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">intervention_targets_per_env</span><span class="p">[</span><span class="n">env</span><span class="p">][</span><span class="n">index</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">parents</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                        <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dag</span><span class="o">.</span><span class="n">predecessors</span><span class="p">(</span><span class="n">index</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span>
                    <span class="p">)</span>
                    <span class="n">coeffs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,))</span>  <span class="c1"># cut edges from parents</span>
                    <span class="n">coeffs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># still use noise</span>
                    <span class="n">f</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                        <span class="n">linear_base_func</span><span class="p">,</span>
                        <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">,</span>
                        <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">,</span>
                        <span class="n">coeffs</span><span class="o">=</span><span class="n">coeffs</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">inverse_jac</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                        <span class="n">linear_inverse_jacobian</span><span class="p">,</span>
                        <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">,</span>
                        <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">,</span>
                        <span class="n">coeffs</span><span class="o">=</span><span class="n">coeffs</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_functions</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
                    <span class="n">inverse_jac</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_inverse_jac</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
                <span class="n">functions_env</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span>
                <span class="n">inverse_jac_env</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">inverse_jac</span>
            <span class="n">functions_per_env</span><span class="p">[</span><span class="n">env</span><span class="p">]</span> <span class="o">=</span> <span class="n">functions_env</span>
            <span class="n">inverse_jac_per_env</span><span class="p">[</span><span class="n">env</span><span class="p">]</span> <span class="o">=</span> <span class="n">inverse_jac_env</span>
        <span class="k">return</span> <span class="n">functions_per_env</span><span class="p">,</span> <span class="n">inverse_jac_per_env</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">




<h4 id="data_generator.scm.LinearSCM.__init__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">adjacency_matrix</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span> <span class="n">intervention_targets_per_env</span><span class="p">,</span> <span class="n">coeffs_low</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">coeffs_high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">coeffs_min_abs_value</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <h6 id="data_generator.scm.LinearSCM.__init__--parameters">Parameters</h6>
<p>adjacency_matrix: np.ndarray, shape (latent_dim, latent_dim)
latent_dim: int
intervention_targets_per_env: Tensor, shape (num_envs, latent_dim)
coeffs_low: float
coeffs_high: float
coeffs_min_abs_value: Optional[float]</p>

          <details class="quote">
            <summary>Source code in <code>data_generator/scm.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">adjacency_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">coeffs_low</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span>
    <span class="n">coeffs_high</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">coeffs_min_abs_value</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    adjacency_matrix: np.ndarray, shape (latent_dim, latent_dim)</span>
<span class="sd">    latent_dim: int</span>
<span class="sd">    intervention_targets_per_env: Tensor, shape (num_envs, latent_dim)</span>
<span class="sd">    coeffs_low: float</span>
<span class="sd">    coeffs_high: float</span>
<span class="sd">    coeffs_min_abs_value: Optional[float]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">adjacency_matrix</span><span class="p">,</span>
        <span class="n">latent_dim</span><span class="p">,</span>
        <span class="n">intervention_targets_per_env</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_low</span> <span class="o">=</span> <span class="n">coeffs_low</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_high</span> <span class="o">=</span> <span class="n">coeffs_high</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_min_abs_value</span> <span class="o">=</span> <span class="n">coeffs_min_abs_value</span>

    <span class="n">base_functions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">base_inverse_jac</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">base_coeff_values</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span><span class="p">):</span>
        <span class="n">parents</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
            <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dag</span><span class="o">.</span><span class="n">predecessors</span><span class="p">(</span><span class="n">index</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span>
        <span class="p">)</span>
        <span class="n">coeffs</span> <span class="o">=</span> <span class="n">sample_coeffs</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_low</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_high</span><span class="p">,</span>
            <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,),</span>
            <span class="n">min_abs_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">coeffs_min_abs_value</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">coeffs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># set the noise coefficient to 1</span>

        <span class="n">base_functions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">partial</span><span class="p">(</span><span class="n">linear_base_func</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">,</span> <span class="n">coeffs</span><span class="o">=</span><span class="n">coeffs</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">base_inverse_jac</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">partial</span><span class="p">(</span>
                <span class="n">linear_inverse_jacobian</span><span class="p">,</span>
                <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">,</span>
                <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">,</span>
                <span class="n">coeffs</span><span class="o">=</span><span class="n">coeffs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">base_coeff_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">coeffs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">base_functions</span> <span class="o">=</span> <span class="n">base_functions</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">base_inverse_jac</span> <span class="o">=</span> <span class="n">base_inverse_jac</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">base_coeff_values</span> <span class="o">=</span> <span class="n">base_coeff_values</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">functions_per_env</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inverse_jac_per_env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">setup_functions_per_env</span><span class="p">(</span>
        <span class="n">intervention_targets_per_env</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h4 id="data_generator.scm.LinearSCM.setup_functions_per_env" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">setup_functions_per_env</span><span class="p">(</span><span class="n">intervention_targets_per_env</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Set up the functions_per_env and inverse_jac_per_env attributes. This is where the linear
causal mechanisms are defined.</p>
<h6 id="data_generator.scm.LinearSCM.setup_functions_per_env--parameters">Parameters</h6>
<p>intervention_targets_per_env: Tensor, shape (num_envs, latent_dim)
    Intervention targets for each environment.</p>
<h6 id="data_generator.scm.LinearSCM.setup_functions_per_env--returns">Returns</h6>
<p>functions_per_env: dict[int, dict[int, callable]]
    Dictionary mapping environment indices to dictionaries mapping latent variable indices to
    functions that implement the causal mechanism. I.e. functions_per_env[env][index] is a
    function that takes two arguments, v and u, and returns a Tensor of shape (batch_size,
    latent_dim) that contains the result of applying the causal mechanism the parents of index.
inverse_jac_per_env: dict[int, dict[int, callable]]
    Dictionary mapping environment indices to dictionaries mapping latent variable indices to
    functions that implement the log of the inverse Jacobian of the causal mechanism. I.e.
    inverse_jac_per_env[env][index] is a function that takes two arguments, v and u, and
    returns a Tensor of shape (batch_size,) that contains the log of the inverse Jacobian of
    the causal mechanism applied to the parents of index.</p>

          <details class="quote">
            <summary>Source code in <code>data_generator/scm.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">setup_functions_per_env</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Tensor</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">callable</span><span class="p">],</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">callable</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Set up the functions_per_env and inverse_jac_per_env attributes. This is where the linear</span>
<span class="sd">    causal mechanisms are defined.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    intervention_targets_per_env: Tensor, shape (num_envs, latent_dim)</span>
<span class="sd">        Intervention targets for each environment.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    functions_per_env: dict[int, dict[int, callable]]</span>
<span class="sd">        Dictionary mapping environment indices to dictionaries mapping latent variable indices to</span>
<span class="sd">        functions that implement the causal mechanism. I.e. functions_per_env[env][index] is a</span>
<span class="sd">        function that takes two arguments, v and u, and returns a Tensor of shape (batch_size,</span>
<span class="sd">        latent_dim) that contains the result of applying the causal mechanism the parents of index.</span>
<span class="sd">    inverse_jac_per_env: dict[int, dict[int, callable]]</span>
<span class="sd">        Dictionary mapping environment indices to dictionaries mapping latent variable indices to</span>
<span class="sd">        functions that implement the log of the inverse Jacobian of the causal mechanism. I.e.</span>
<span class="sd">        inverse_jac_per_env[env][index] is a function that takes two arguments, v and u, and</span>
<span class="sd">        returns a Tensor of shape (batch_size,) that contains the log of the inverse Jacobian of</span>
<span class="sd">        the causal mechanism applied to the parents of index.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">functions_per_env</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">inverse_jac_per_env</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">num_envs</span> <span class="o">=</span> <span class="n">intervention_targets_per_env</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">env</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_envs</span><span class="p">):</span>
        <span class="n">functions_env</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">inverse_jac_env</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">topological_order</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">intervention_targets_per_env</span><span class="p">[</span><span class="n">env</span><span class="p">][</span><span class="n">index</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">parents</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                    <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dag</span><span class="o">.</span><span class="n">predecessors</span><span class="p">(</span><span class="n">index</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span>
                <span class="p">)</span>
                <span class="n">coeffs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,))</span>  <span class="c1"># cut edges from parents</span>
                <span class="n">coeffs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># still use noise</span>
                <span class="n">f</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                    <span class="n">linear_base_func</span><span class="p">,</span>
                    <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">,</span>
                    <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">,</span>
                    <span class="n">coeffs</span><span class="o">=</span><span class="n">coeffs</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">inverse_jac</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                    <span class="n">linear_inverse_jacobian</span><span class="p">,</span>
                    <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">,</span>
                    <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">,</span>
                    <span class="n">coeffs</span><span class="o">=</span><span class="n">coeffs</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_functions</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
                <span class="n">inverse_jac</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_inverse_jac</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
            <span class="n">functions_env</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span>
            <span class="n">inverse_jac_env</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">inverse_jac</span>
        <span class="n">functions_per_env</span><span class="p">[</span><span class="n">env</span><span class="p">]</span> <span class="o">=</span> <span class="n">functions_env</span>
        <span class="n">inverse_jac_per_env</span><span class="p">[</span><span class="n">env</span><span class="p">]</span> <span class="o">=</span> <span class="n">inverse_jac_env</span>
    <span class="k">return</span> <span class="n">functions_per_env</span><span class="p">,</span> <span class="n">inverse_jac_per_env</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">




<h3 id="data_generator.scm.LocationScaleSCM" class="doc doc-heading">
          <code>LocationScaleSCM</code>


</h3>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="data_generator.scm.MultiEnvLatentSCM" href="#data_generator.scm.MultiEnvLatentSCM">MultiEnvLatentSCM</a></code></p>

  
      <p>Multi-environment latent SCM, where all causal mechanisms are location-scale functions [1] of the form
v_i = snr * f_loc(pa_i) + f_scale(u_i), where f_loc and f_scale are random nonlinear functions, pa_i
are the parents of v_i, and u_i is the exogenous noise variable corresponding to v_i. snr is the
signal-to-noise ratio.</p>
<p>Inherits all attributes and methods from MultiEnvLatentSCM.</p>
<h5 id="data_generator.scm.LocationScaleSCM--additional-attributes">Additional attributes</h5>
<p>n_nonlinearities : int
    Number of nonlinearities in the location-scale functions. Default: 3.
snr : float
    Signal-to-noise ratio. Default: 1.0.
base_functions : list[callable]
    List of base functions that implement the location-scale functions for each latent variable in the
    unintervened (observational) environment.
base_inverse_jac : list[callable]
    List of base functions that implement the log of the inverse Jacobian of the location-scale functions
    for each latent variable in the unintervened (observational) environment.</p>
<h5 id="data_generator.scm.LocationScaleSCM--additional-methods">Additional methods</h5>
<p>setup_functions_per_env(intervention_targets_per_env: Tensor) -&gt; tuple[dict[int, callable], dict[int, callable]]
    Set up the functions_per_env and inverse_jac_per_env attributes. This is where the causal mechanisms
    based on the location-scale functions are defined.</p>
<h5 id="data_generator.scm.LocationScaleSCM--references">References</h5>
<p>[1] https://en.wikipedia.org/wiki/Location%E2%80%93scale_family</p>

            <details class="quote">
              <summary>Source code in <code>data_generator/scm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">LocationScaleSCM</span><span class="p">(</span><span class="n">MultiEnvLatentSCM</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Multi-environment latent SCM, where all causal mechanisms are location-scale functions [1] of the form</span>
<span class="sd">    v_i = snr * f_loc(pa_i) + f_scale(u_i), where f_loc and f_scale are random nonlinear functions, pa_i</span>
<span class="sd">    are the parents of v_i, and u_i is the exogenous noise variable corresponding to v_i. snr is the</span>
<span class="sd">    signal-to-noise ratio.</span>

<span class="sd">    Inherits all attributes and methods from MultiEnvLatentSCM.</span>

<span class="sd">    Additional attributes</span>
<span class="sd">    ---------------------</span>
<span class="sd">    n_nonlinearities : int</span>
<span class="sd">        Number of nonlinearities in the location-scale functions. Default: 3.</span>
<span class="sd">    snr : float</span>
<span class="sd">        Signal-to-noise ratio. Default: 1.0.</span>
<span class="sd">    base_functions : list[callable]</span>
<span class="sd">        List of base functions that implement the location-scale functions for each latent variable in the</span>
<span class="sd">        unintervened (observational) environment.</span>
<span class="sd">    base_inverse_jac : list[callable]</span>
<span class="sd">        List of base functions that implement the log of the inverse Jacobian of the location-scale functions</span>
<span class="sd">        for each latent variable in the unintervened (observational) environment.</span>

<span class="sd">    Additional methods</span>
<span class="sd">    ------------------</span>
<span class="sd">    setup_functions_per_env(intervention_targets_per_env: Tensor) -&gt; tuple[dict[int, callable], dict[int, callable]]</span>
<span class="sd">        Set up the functions_per_env and inverse_jac_per_env attributes. This is where the causal mechanisms</span>
<span class="sd">        based on the location-scale functions are defined.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] https://en.wikipedia.org/wiki/Location%E2%80%93scale_family</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">adjacency_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">n_nonlinearities</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">snr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">adjacency_matrix</span><span class="p">,</span>
            <span class="n">latent_dim</span><span class="p">,</span>
            <span class="n">intervention_targets_per_env</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_nonlinearities</span> <span class="o">=</span> <span class="n">n_nonlinearities</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">snr</span> <span class="o">=</span> <span class="n">snr</span>

        <span class="n">base_functions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">base_inverse_jac</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span><span class="p">):</span>
            <span class="n">parents</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dag</span><span class="o">.</span><span class="n">predecessors</span><span class="p">(</span><span class="n">index</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span>
            <span class="p">)</span>
            <span class="n">f</span><span class="p">,</span> <span class="n">inverse_jac</span> <span class="o">=</span> <span class="n">make_location_scale_function</span><span class="p">(</span>
                <span class="n">index</span><span class="p">,</span> <span class="n">parents</span><span class="p">,</span> <span class="n">n_nonlinearities</span><span class="p">,</span> <span class="n">snr</span>
            <span class="p">)</span>
            <span class="n">base_functions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
            <span class="n">base_inverse_jac</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inverse_jac</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_functions</span> <span class="o">=</span> <span class="n">base_functions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_inverse_jac</span> <span class="o">=</span> <span class="n">base_inverse_jac</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">functions_per_env</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inverse_jac_per_env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">setup_functions_per_env</span><span class="p">(</span>
            <span class="n">intervention_targets_per_env</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">setup_functions_per_env</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">callable</span><span class="p">],</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">callable</span><span class="p">]]:</span>
        <span class="n">functions_per_env</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">inverse_jac_per_env</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">num_envs</span> <span class="o">=</span> <span class="n">intervention_targets_per_env</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">env</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_envs</span><span class="p">):</span>
            <span class="n">functions_env</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">inverse_jac_env</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">topological_order</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">intervention_targets_per_env</span><span class="p">[</span><span class="n">env</span><span class="p">][</span><span class="n">index</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">parents</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="n">f</span><span class="p">,</span> <span class="n">inverse_jac</span> <span class="o">=</span> <span class="n">make_location_scale_function</span><span class="p">(</span>
                        <span class="n">index</span><span class="p">,</span> <span class="n">parents</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_nonlinearities</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">snr</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_functions</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
                    <span class="n">inverse_jac</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_inverse_jac</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
                <span class="n">functions_env</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span>
                <span class="n">inverse_jac_env</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">inverse_jac</span>
            <span class="n">functions_per_env</span><span class="p">[</span><span class="n">env</span><span class="p">]</span> <span class="o">=</span> <span class="n">functions_env</span>
            <span class="n">inverse_jac_per_env</span><span class="p">[</span><span class="n">env</span><span class="p">]</span> <span class="o">=</span> <span class="n">inverse_jac_env</span>
        <span class="k">return</span> <span class="n">functions_per_env</span><span class="p">,</span> <span class="n">inverse_jac_per_env</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>

<div class="doc doc-object doc-class">




<h3 id="data_generator.scm.MultiEnvLatentSCM" class="doc doc-heading">
          <code>MultiEnvLatentSCM</code>


</h3>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><span title="abc.ABC">ABC</span></code></p>

  
      <p>Base class for multi-environment latent SCM.</p>
<p>In environments where a variable is intervened on, the dependencies of the variable are cut. Note that this
class only implements the causal mechanisms. The exogenous noise variables, which mayb also shift under
interventions, are implemented in the noise generator.</p>
<h5 id="data_generator.scm.MultiEnvLatentSCM--attributes">Attributes</h5>
<p>adjacency_matrix : np.ndarray, shape (latent_dim, latent_dim)
    Adjacency matrix of the SCM.
latent_dim : int
    Dimension of the latent space.
intervention_targets_per_env : Tensor, shape (num_envs, latent_dim)
    Binary tensor indicating which variables are intervened on in each environment.
dag : nx.DiGraph
    Directed acyclic graph representing the causal structure.
topological_order : list[int]
    Topological order of the causal graph.
functions_per_env : dict[int, dict[int, callable]]
    Dictionary mapping environment indices to dictionaries mapping latent variable indices to
    functions that implement the causal mechanism. I.e. functions_per_env[env][index] is a
    function that takes two arguments, v and u, and returns a Tensor of shape (batch_size,
    latent_dim) that contains the result of applying the causal mechanism the parents of index.
inverse_jac_per_env : dict[int, dict[int, callable]]
    Dictionary mapping environment indices to dictionaries mapping latent variable indices to
    functions that implement the log of the inverse Jacobian of the causal mechanism. I.e.
    inverse_jac_per_env[env][index] is a function that takes two arguments, v and u, and
    returns a Tensor of shape (batch_size,) that contains the log of the inverse Jacobian of
    the causal mechanism applied to the parents of index.</p>
<h5 id="data_generator.scm.MultiEnvLatentSCM--methods">Methods</h5>
<p>push_forward(u: Tensor, env: int) -&gt; Tensor
    Push forward the latent variable u through the SCM in environment env.
log_inverse_jacobian(v: Tensor, u: Tensor, env: int) -&gt; Tensor
    Compute the log of the inverse Jacobian of the SCM in environment env at v and u.</p>

            <details class="quote">
              <summary>Source code in <code>data_generator/scm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MultiEnvLatentSCM</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for multi-environment latent SCM.</span>

<span class="sd">    In environments where a variable is intervened on, the dependencies of the variable are cut. Note that this</span>
<span class="sd">    class only implements the causal mechanisms. The exogenous noise variables, which mayb also shift under</span>
<span class="sd">    interventions, are implemented in the noise generator.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    adjacency_matrix : np.ndarray, shape (latent_dim, latent_dim)</span>
<span class="sd">        Adjacency matrix of the SCM.</span>
<span class="sd">    latent_dim : int</span>
<span class="sd">        Dimension of the latent space.</span>
<span class="sd">    intervention_targets_per_env : Tensor, shape (num_envs, latent_dim)</span>
<span class="sd">        Binary tensor indicating which variables are intervened on in each environment.</span>
<span class="sd">    dag : nx.DiGraph</span>
<span class="sd">        Directed acyclic graph representing the causal structure.</span>
<span class="sd">    topological_order : list[int]</span>
<span class="sd">        Topological order of the causal graph.</span>
<span class="sd">    functions_per_env : dict[int, dict[int, callable]]</span>
<span class="sd">        Dictionary mapping environment indices to dictionaries mapping latent variable indices to</span>
<span class="sd">        functions that implement the causal mechanism. I.e. functions_per_env[env][index] is a</span>
<span class="sd">        function that takes two arguments, v and u, and returns a Tensor of shape (batch_size,</span>
<span class="sd">        latent_dim) that contains the result of applying the causal mechanism the parents of index.</span>
<span class="sd">    inverse_jac_per_env : dict[int, dict[int, callable]]</span>
<span class="sd">        Dictionary mapping environment indices to dictionaries mapping latent variable indices to</span>
<span class="sd">        functions that implement the log of the inverse Jacobian of the causal mechanism. I.e.</span>
<span class="sd">        inverse_jac_per_env[env][index] is a function that takes two arguments, v and u, and</span>
<span class="sd">        returns a Tensor of shape (batch_size,) that contains the log of the inverse Jacobian of</span>
<span class="sd">        the causal mechanism applied to the parents of index.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    push_forward(u: Tensor, env: int) -&gt; Tensor</span>
<span class="sd">        Push forward the latent variable u through the SCM in environment env.</span>
<span class="sd">    log_inverse_jacobian(v: Tensor, u: Tensor, env: int) -&gt; Tensor</span>
<span class="sd">        Compute the log of the inverse Jacobian of the SCM in environment env at v and u.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">adjacency_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        adjacency_matrix: np.ndarray, shape (latent_dim, latent_dim)</span>
<span class="sd">        latent_dim: int</span>
<span class="sd">        intervention_targets_per_env: Tensor, shape (num_envs, latent_dim)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adjacency_matrix</span> <span class="o">=</span> <span class="n">adjacency_matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">latent_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intervention_targets_per_env</span> <span class="o">=</span> <span class="n">intervention_targets_per_env</span>
        <span class="k">assert</span> <span class="n">adjacency_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">adjacency_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">latent_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dag</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">(</span><span class="n">adjacency_matrix</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">topological_order</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">topological_sort</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dag</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">functions_per_env</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inverse_jac_per_env</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">push_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Push forward the latent variable u through the SCM in environment env.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        u: Tensor, shape (num_samples, latent_dim)</span>
<span class="sd">            Samples of the exogenous noise variables.</span>
<span class="sd">        env: int</span>
<span class="sd">            Environment index.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        v: Tensor, shape (num_samples, latent_dim)</span>
<span class="sd">            Samples of the latent variables.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nan</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">topological_order</span><span class="p">:</span>
            <span class="n">f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">functions_per_env</span><span class="p">[</span><span class="n">env</span><span class="p">][</span><span class="n">index</span><span class="p">]</span>
            <span class="n">v</span><span class="p">[:,</span> <span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">u</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">v</span>

    <span class="k">def</span> <span class="nf">log_inverse_jacobian</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">u</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the log of the inverse Jacobian of the SCM in environment env at v and u.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        v: Tensor, shape (num_samples, latent_dim)</span>
<span class="sd">            Samples of the latent variables.</span>
<span class="sd">        u: Tensor, shape (num_samples, latent_dim)</span>
<span class="sd">            Samples of the exogenous noise variables.</span>
<span class="sd">        env: int</span>
<span class="sd">            Environment index.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        log_inv_jac: Tensor, shape (num_samples,)</span>
<span class="sd">            Log of the inverse Jacobian of the SCM at v and u.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_inv_jac</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">topological_order</span><span class="p">:</span>
            <span class="n">log_inv_jac</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inverse_jac_per_env</span><span class="p">[</span><span class="n">env</span><span class="p">][</span><span class="n">index</span><span class="p">](</span><span class="n">v</span><span class="p">,</span> <span class="n">u</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">log_inv_jac</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">




<h4 id="data_generator.scm.MultiEnvLatentSCM.__init__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">adjacency_matrix</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span> <span class="n">intervention_targets_per_env</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <h6 id="data_generator.scm.MultiEnvLatentSCM.__init__--parameters">Parameters</h6>
<p>adjacency_matrix: np.ndarray, shape (latent_dim, latent_dim)
latent_dim: int
intervention_targets_per_env: Tensor, shape (num_envs, latent_dim)</p>

          <details class="quote">
            <summary>Source code in <code>data_generator/scm.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">adjacency_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    adjacency_matrix: np.ndarray, shape (latent_dim, latent_dim)</span>
<span class="sd">    latent_dim: int</span>
<span class="sd">    intervention_targets_per_env: Tensor, shape (num_envs, latent_dim)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">adjacency_matrix</span> <span class="o">=</span> <span class="n">adjacency_matrix</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">latent_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">intervention_targets_per_env</span> <span class="o">=</span> <span class="n">intervention_targets_per_env</span>
    <span class="k">assert</span> <span class="n">adjacency_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">adjacency_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">latent_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dag</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">(</span><span class="n">adjacency_matrix</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">topological_order</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">topological_sort</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dag</span><span class="p">))</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">functions_per_env</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">inverse_jac_per_env</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h4 id="data_generator.scm.MultiEnvLatentSCM.log_inverse_jacobian" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">log_inverse_jacobian</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">env</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Compute the log of the inverse Jacobian of the SCM in environment env at v and u.</p>
<h6 id="data_generator.scm.MultiEnvLatentSCM.log_inverse_jacobian--parameters">Parameters</h6>
<p>v: Tensor, shape (num_samples, latent_dim)
    Samples of the latent variables.
u: Tensor, shape (num_samples, latent_dim)
    Samples of the exogenous noise variables.
env: int
    Environment index.</p>
<h6 id="data_generator.scm.MultiEnvLatentSCM.log_inverse_jacobian--returns">Returns</h6>
<p>log_inv_jac: Tensor, shape (num_samples,)
    Log of the inverse Jacobian of the SCM at v and u.</p>

          <details class="quote">
            <summary>Source code in <code>data_generator/scm.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">log_inverse_jacobian</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">u</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the log of the inverse Jacobian of the SCM in environment env at v and u.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    v: Tensor, shape (num_samples, latent_dim)</span>
<span class="sd">        Samples of the latent variables.</span>
<span class="sd">    u: Tensor, shape (num_samples, latent_dim)</span>
<span class="sd">        Samples of the exogenous noise variables.</span>
<span class="sd">    env: int</span>
<span class="sd">        Environment index.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    log_inv_jac: Tensor, shape (num_samples,)</span>
<span class="sd">        Log of the inverse Jacobian of the SCM at v and u.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log_inv_jac</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">topological_order</span><span class="p">:</span>
        <span class="n">log_inv_jac</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inverse_jac_per_env</span><span class="p">[</span><span class="n">env</span><span class="p">][</span><span class="n">index</span><span class="p">](</span><span class="n">v</span><span class="p">,</span> <span class="n">u</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">log_inv_jac</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h4 id="data_generator.scm.MultiEnvLatentSCM.push_forward" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">push_forward</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">env</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>Push forward the latent variable u through the SCM in environment env.</p>
<h6 id="data_generator.scm.MultiEnvLatentSCM.push_forward--parameters">Parameters</h6>
<p>u: Tensor, shape (num_samples, latent_dim)
    Samples of the exogenous noise variables.
env: int
    Environment index.</p>
<h6 id="data_generator.scm.MultiEnvLatentSCM.push_forward--returns">Returns</h6>
<p>v: Tensor, shape (num_samples, latent_dim)
    Samples of the latent variables.</p>

          <details class="quote">
            <summary>Source code in <code>data_generator/scm.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">push_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Push forward the latent variable u through the SCM in environment env.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    u: Tensor, shape (num_samples, latent_dim)</span>
<span class="sd">        Samples of the exogenous noise variables.</span>
<span class="sd">    env: int</span>
<span class="sd">        Environment index.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    v: Tensor, shape (num_samples, latent_dim)</span>
<span class="sd">        Samples of the latent variables.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nan</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">topological_order</span><span class="p">:</span>
        <span class="n">f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">functions_per_env</span><span class="p">[</span><span class="n">env</span><span class="p">][</span><span class="n">index</span><span class="p">]</span>
        <span class="n">v</span><span class="p">[:,</span> <span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">u</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">v</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div>


  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<a id="model"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">










<div class="doc doc-object doc-module">




<h2 id="model.cauca_model" class="doc doc-heading">
          <code>cauca_model</code>


</h2>

  <div class="doc doc-contents ">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">




<h3 id="model.cauca_model.CauCAModel" class="doc doc-heading">
          <code>CauCAModel</code>


</h3>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><span title="pytorch_lightning.LightningModule">LightningModule</span></code>, <code><span title="abc.ABC">ABC</span></code></p>

  
      <p>Base class for Causal Component Analysis (CauCA) models. It implements the
training loop and the evaluation metrics.</p>
<h5 id="model.cauca_model.CauCAModel--attributes">Attributes</h5>
<p>latent_dim : int
    Dimensionality of the latent space.
adjacency_matrix : np.ndarray, shape (num_nodes, num_nodes)
    Adjacency matrix of the causal graph assumed by the model. This is not necessarily
    the true adjacency matrix of the data generating process (see below).
adjacency_matrix_gt : np.ndarray, shape (num_nodes, num_nodes)
    Ground truth adjacency matrix of the causal graph. This is the adjacency matrix
    of the data generating process.
adjacency_misspecified : bool
    Whether the adjacency matrix is misspecified. If True, the model assumes a wrong
    adjacency matrix.
lr : float
    Learning rate for the optimizer.
weight_decay : float
    Weight decay for the optimizer.
lr_scheduler : str
    Learning rate scheduler to use. If None, no scheduler is used. Options are
    "cosine" or None. Default: None.
lr_min : float
    Minimum learning rate for the scheduler. Default: 0.0.
encoder : CauCAEncoder
    The CauCA encoder. Needs to be set in subclasses.</p>
<h5 id="model.cauca_model.CauCAModel--methods">Methods</h5>
<p>training_step(batch, batch_idx) -&gt; Tensor
    Training step.
validation_step(batch, batch_idx) -&gt; dict[str, Tensor]
    Validation step: basically passes data to validation_epoch_end.
validation_epoch_end(outputs) -&gt; None
    Computes validation metrics across all validation data.
test_step(batch, batch_idx) -&gt; dict[str, Tensor]
    Test step: basically passes data to test_epoch_end.
test_epoch_end(outputs) -&gt; None
    Computes test metrics across all test data.
configure_optimizers() -&gt; dict | torch.optim.Optimizer
    Configures the optimizer and learning rate scheduler.
forward(x) -&gt; torch.Tensor
    Computes the latent variables from the observed data.
on_before_optimizer_step(optimizer, optimizer_idx) -&gt; None
    Callback that is called before each optimizer step. It ensures that some gradients
    are set to zero to fix some causal mechanisms. See documentation of ParamMultiEnvCausalDistribution
    for more details.
set_adjacency(adjacency_matrix, adjacency_misspecified) -&gt; np.ndarray
    Sets the adjacency matrix and possibly changes it if it is misspecified.</p>

            <details class="quote">
              <summary>Source code in <code>model/cauca_model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CauCAModel</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for Causal Component Analysis (CauCA) models. It implements the</span>
<span class="sd">    training loop and the evaluation metrics.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    latent_dim : int</span>
<span class="sd">        Dimensionality of the latent space.</span>
<span class="sd">    adjacency_matrix : np.ndarray, shape (num_nodes, num_nodes)</span>
<span class="sd">        Adjacency matrix of the causal graph assumed by the model. This is not necessarily</span>
<span class="sd">        the true adjacency matrix of the data generating process (see below).</span>
<span class="sd">    adjacency_matrix_gt : np.ndarray, shape (num_nodes, num_nodes)</span>
<span class="sd">        Ground truth adjacency matrix of the causal graph. This is the adjacency matrix</span>
<span class="sd">        of the data generating process.</span>
<span class="sd">    adjacency_misspecified : bool</span>
<span class="sd">        Whether the adjacency matrix is misspecified. If True, the model assumes a wrong</span>
<span class="sd">        adjacency matrix.</span>
<span class="sd">    lr : float</span>
<span class="sd">        Learning rate for the optimizer.</span>
<span class="sd">    weight_decay : float</span>
<span class="sd">        Weight decay for the optimizer.</span>
<span class="sd">    lr_scheduler : str</span>
<span class="sd">        Learning rate scheduler to use. If None, no scheduler is used. Options are</span>
<span class="sd">        &quot;cosine&quot; or None. Default: None.</span>
<span class="sd">    lr_min : float</span>
<span class="sd">        Minimum learning rate for the scheduler. Default: 0.0.</span>
<span class="sd">    encoder : CauCAEncoder</span>
<span class="sd">        The CauCA encoder. Needs to be set in subclasses.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    training_step(batch, batch_idx) -&gt; Tensor</span>
<span class="sd">        Training step.</span>
<span class="sd">    validation_step(batch, batch_idx) -&gt; dict[str, Tensor]</span>
<span class="sd">        Validation step: basically passes data to validation_epoch_end.</span>
<span class="sd">    validation_epoch_end(outputs) -&gt; None</span>
<span class="sd">        Computes validation metrics across all validation data.</span>
<span class="sd">    test_step(batch, batch_idx) -&gt; dict[str, Tensor]</span>
<span class="sd">        Test step: basically passes data to test_epoch_end.</span>
<span class="sd">    test_epoch_end(outputs) -&gt; None</span>
<span class="sd">        Computes test metrics across all test data.</span>
<span class="sd">    configure_optimizers() -&gt; dict | torch.optim.Optimizer</span>
<span class="sd">        Configures the optimizer and learning rate scheduler.</span>
<span class="sd">    forward(x) -&gt; torch.Tensor</span>
<span class="sd">        Computes the latent variables from the observed data.</span>
<span class="sd">    on_before_optimizer_step(optimizer, optimizer_idx) -&gt; None</span>
<span class="sd">        Callback that is called before each optimizer step. It ensures that some gradients</span>
<span class="sd">        are set to zero to fix some causal mechanisms. See documentation of ParamMultiEnvCausalDistribution</span>
<span class="sd">        for more details.</span>
<span class="sd">    set_adjacency(adjacency_matrix, adjacency_misspecified) -&gt; np.ndarray</span>
<span class="sd">        Sets the adjacency matrix and possibly changes it if it is misspecified.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">adjacency_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-2</span><span class="p">,</span>
        <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">lr_scheduler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">lr_min</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">adjacency_misspecified</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">latent_dim</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">adjacency_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">set_adjacency</span><span class="p">(</span>
            <span class="n">adjacency_matrix</span><span class="p">,</span> <span class="n">adjacency_misspecified</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adjacency_matrix_gt</span> <span class="o">=</span> <span class="n">adjacency_matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adjacency_misspecified</span> <span class="o">=</span> <span class="n">adjacency_misspecified</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span> <span class="o">=</span> <span class="n">weight_decay</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_min</span> <span class="o">=</span> <span class="n">lr_min</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># needs to be set in subclasses</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">set_adjacency</span><span class="p">(</span>
        <span class="n">adjacency_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">adjacency_misspecified</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">adjacency_misspecified</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">adjacency_matrix</span>

        <span class="k">if</span> <span class="n">adjacency_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">adjacency_matrix</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># for 2 variables, if adjacency matrix is [[0, 0], [0, 0]], then</span>
            <span class="c1"># replace with [[0, 1], [0, 0]]</span>

            <span class="n">adjacency_matrix_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">adjacency_matrix</span><span class="p">)</span>
            <span class="n">adjacency_matrix_out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">return</span> <span class="n">adjacency_matrix_out</span>
        <span class="k">elif</span> <span class="n">adjacency_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Adjacency misspecification not supported for empty adjacency matrix for &gt;2 variables&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">adjacency_matrix</span><span class="o">.</span><span class="n">T</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">int_target</span><span class="p">,</span> <span class="n">log_prob_gt</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">log_prob</span><span class="p">,</span> <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">multi_env_log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">int_target</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">log_prob</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;train_loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">int_target</span><span class="p">,</span> <span class="n">log_prob_gt</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">log_prob</span><span class="p">,</span> <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">multi_env_log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">int_target</span><span class="p">)</span>

        <span class="n">v_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;log_prob&quot;</span><span class="p">:</span> <span class="n">log_prob</span><span class="p">,</span>
            <span class="s2">&quot;log_prob_gt&quot;</span><span class="p">:</span> <span class="n">log_prob_gt</span><span class="p">,</span>
            <span class="s2">&quot;v&quot;</span><span class="p">:</span> <span class="n">v</span><span class="p">,</span>
            <span class="s2">&quot;v_hat&quot;</span><span class="p">:</span> <span class="n">v_hat</span><span class="p">,</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">validation_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">o</span><span class="p">[</span><span class="s2">&quot;log_prob&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">])</span>
        <span class="n">log_prob_gt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">o</span><span class="p">[</span><span class="s2">&quot;log_prob_gt&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">])</span>

        <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">o</span><span class="p">[</span><span class="s2">&quot;v&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">])</span>
        <span class="n">v_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">o</span><span class="p">[</span><span class="s2">&quot;v_hat&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">])</span>
        <span class="n">mcc</span> <span class="o">=</span> <span class="n">mean_correlation_coefficient</span><span class="p">(</span><span class="n">v_hat</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
        <span class="n">mcc_spearman</span> <span class="o">=</span> <span class="n">mean_correlation_coefficient</span><span class="p">(</span><span class="n">v_hat</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;spearman&quot;</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">log_prob</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">loss_gt</span> <span class="o">=</span> <span class="o">-</span><span class="n">log_prob_gt</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;val_loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;val_loss_gt&quot;</span><span class="p">,</span> <span class="n">loss_gt</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;val_mcc&quot;</span><span class="p">,</span> <span class="n">mcc</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">mcc_value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mcc</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;val_mcc_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mcc_value</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;val_mcc_spearman&quot;</span><span class="p">,</span> <span class="n">mcc_spearman</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">mcc_value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mcc_spearman</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;val_mcc_spearman_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mcc_value</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]]:</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">int_target</span><span class="p">,</span> <span class="n">log_prob_gt</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">log_prob</span><span class="p">,</span> <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">multi_env_log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">int_target</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;log_prob&quot;</span><span class="p">:</span> <span class="n">log_prob</span><span class="p">,</span>
            <span class="s2">&quot;v&quot;</span><span class="p">:</span> <span class="n">v</span><span class="p">,</span>
            <span class="s2">&quot;v_hat&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">test_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">o</span><span class="p">[</span><span class="s2">&quot;log_prob&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">])</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">log_prob</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">o</span><span class="p">[</span><span class="s2">&quot;v&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">])</span>
        <span class="n">v_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">o</span><span class="p">[</span><span class="s2">&quot;v_hat&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">])</span>
        <span class="n">mcc</span> <span class="o">=</span> <span class="n">mean_correlation_coefficient</span><span class="p">(</span><span class="n">v_hat</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;test_loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;test_mcc&quot;</span><span class="p">,</span> <span class="n">mcc</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">mcc_value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mcc</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;test_mcc_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mcc_value</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">:</span>
        <span class="n">config_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span>
        <span class="p">)</span>
        <span class="n">config_dict</span><span class="p">[</span><span class="s2">&quot;optimizer&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimizer</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span> <span class="o">==</span> <span class="s2">&quot;cosine&quot;</span><span class="p">:</span>
            <span class="c1"># cosine learning rate annealing</span>
            <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">CosineAnnealingLR</span><span class="p">(</span>
                <span class="n">optimizer</span><span class="p">,</span>
                <span class="n">T_max</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">max_epochs</span><span class="p">,</span>
                <span class="n">eta_min</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr_min</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">lr_scheduler_config</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;scheduler&quot;</span><span class="p">:</span> <span class="n">lr_scheduler</span><span class="p">,</span>
                <span class="s2">&quot;interval&quot;</span><span class="p">:</span> <span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="n">config_dict</span><span class="p">[</span><span class="s2">&quot;lr_scheduler&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr_scheduler_config</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">optimizer</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown lr_scheduler: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">config_dict</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">v_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">v_hat</span>

    <span class="k">def</span> <span class="nf">on_before_optimizer_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">Optimizer</span><span class="p">,</span> <span class="n">optimizer_idx</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">num_envs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">intervention_targets_per_env</span><span class="p">)</span>
        <span class="n">num_vars</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># set gradients to fixed q0 parameters to zero</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">trainable</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">param_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                    <span class="n">product</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_envs</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_vars</span><span class="p">))</span>
                <span class="p">):</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">noise_means_requires_grad</span><span class="p">[</span><span class="n">env</span><span class="p">][</span><span class="n">i</span><span class="p">]:</span>
                        <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">noise_means</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span>
                            <span class="n">param_idx</span>
                        <span class="p">]</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">noise_stds_requires_grad</span><span class="p">[</span><span class="n">env</span><span class="p">][</span><span class="n">i</span><span class="p">]:</span>
                        <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">noise_stds</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span>
                            <span class="n">param_idx</span>
                        <span class="p">]</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="k">pass</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>

<div class="doc doc-object doc-class">




<h3 id="model.cauca_model.LinearCauCAModel" class="doc doc-heading">
          <code>LinearCauCAModel</code>


</h3>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="model.cauca_model.CauCAModel" href="#model.cauca_model.CauCAModel">CauCAModel</a></code></p>

  
      <p>CauCA model with linear unmixing function.</p>

            <details class="quote">
              <summary>Source code in <code>model/cauca_model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">LinearCauCAModel</span><span class="p">(</span><span class="n">CauCAModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    CauCA model with linear unmixing function.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">adjacency_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-2</span><span class="p">,</span>
        <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">lr_scheduler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">lr_min</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">adjacency_misspecified</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">fix_mechanisms</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">nonparametric_base_distr</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span>
            <span class="n">adjacency_matrix</span><span class="o">=</span><span class="n">adjacency_matrix</span><span class="p">,</span>
            <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
            <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler</span><span class="p">,</span>
            <span class="n">lr_min</span><span class="o">=</span><span class="n">lr_min</span><span class="p">,</span>
            <span class="n">adjacency_misspecified</span><span class="o">=</span><span class="n">adjacency_misspecified</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">LinearCauCAEncoder</span><span class="p">(</span>
            <span class="n">latent_dim</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">,</span>  <span class="c1"># this is the misspecified adjacency matrix if adjacency_misspecified=True</span>
            <span class="n">intervention_targets_per_env</span><span class="o">=</span><span class="n">intervention_targets_per_env</span><span class="p">,</span>
            <span class="n">fix_mechanisms</span><span class="o">=</span><span class="n">fix_mechanisms</span><span class="p">,</span>
            <span class="n">nonparametric_base_distr</span><span class="o">=</span><span class="n">nonparametric_base_distr</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>

<div class="doc doc-object doc-class">




<h3 id="model.cauca_model.NaiveNonlinearModel" class="doc doc-heading">
          <code>NaiveNonlinearModel</code>


</h3>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="model.cauca_model.CauCAModel" href="#model.cauca_model.CauCAModel">CauCAModel</a></code></p>

  
      <p>Naive CauCA model with nonlinear unmixing function. It assumes no causal dependencies.</p>

            <details class="quote">
              <summary>Source code in <code>model/cauca_model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">NaiveNonlinearModel</span><span class="p">(</span><span class="n">CauCAModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Naive CauCA model with nonlinear unmixing function. It assumes no causal dependencies.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">adjacency_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-2</span><span class="p">,</span>
        <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">lr_scheduler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">lr_min</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">adjacency_misspecified</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">k_flows</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">net_hidden_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
        <span class="n">net_hidden_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span>
            <span class="n">adjacency_matrix</span><span class="o">=</span><span class="n">adjacency_matrix</span><span class="p">,</span>
            <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
            <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler</span><span class="p">,</span>
            <span class="n">lr_min</span><span class="o">=</span><span class="n">lr_min</span><span class="p">,</span>
            <span class="n">adjacency_misspecified</span><span class="o">=</span><span class="n">adjacency_misspecified</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">NaiveEncoder</span><span class="p">(</span>
            <span class="n">latent_dim</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">,</span>  <span class="c1"># this is the misspecified adjacency matrix if adjacency_misspecified=True</span>
            <span class="n">K</span><span class="o">=</span><span class="n">k_flows</span><span class="p">,</span>
            <span class="n">intervention_targets_per_env</span><span class="o">=</span><span class="n">intervention_targets_per_env</span><span class="p">,</span>
            <span class="n">net_hidden_dim</span><span class="o">=</span><span class="n">net_hidden_dim</span><span class="p">,</span>
            <span class="n">net_hidden_layers</span><span class="o">=</span><span class="n">net_hidden_layers</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>

<div class="doc doc-object doc-class">




<h3 id="model.cauca_model.NonlinearCauCAModel" class="doc doc-heading">
          <code>NonlinearCauCAModel</code>


</h3>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="model.cauca_model.CauCAModel" href="#model.cauca_model.CauCAModel">CauCAModel</a></code></p>

  
      <p>CauCA model with nonlinear unmixing function.</p>
<h5 id="model.cauca_model.NonlinearCauCAModel--additional-attributes">Additional attributes</h5>
<p>k_flows : int
    Number of flows to use in the nonlinear unmixing function. Default: 1.
net_hidden_dim : int
    Hidden dimension of the neural network used in the nonlinear unmixing function. Default: 128.
net_hidden_layers : int
    Number of hidden layers of the neural network used in the nonlinear unmixing function. Default: 3.
fix_mechanisms : bool
    Some mechanisms can be fixed to a simple gaussian distribution without loss of generality.
    This has only an effect for the parametric base distribution. If True, these mechanisms are fixed.
    Default: True.
fix_all_intervention_targets : bool
    When fixable mechanisms are fixed, this parameter determines whether all intervention targets
    are fixed (option 1) or all intervention targets which are non-root nodes together with all
    non-intervened root nodes (option 2). See documentation of ParamMultiEnvCausalDistribution
    for more details. Default: False.
nonparametric_base_distr : bool
    Whether to use a nonparametric base distribution for the flows. If false, a parametric linear
    gaussian causal base distribution is used. Default: False.
K_cbn : int
    Number of flows to use in the nonlinear nonparametric base distribution. Default: 3.
net_hidden_dim_cbn : int
    Hidden dimension of the neural network used in the nonlinear nonparametric base distribution. Default: 128.
net_hidden_layers_cbn : int
    Number of hidden layers of the neural network used in the nonlinear nonparametric base distribution. Default: 3.</p>

            <details class="quote">
              <summary>Source code in <code>model/cauca_model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">NonlinearCauCAModel</span><span class="p">(</span><span class="n">CauCAModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    CauCA model with nonlinear unmixing function.</span>

<span class="sd">    Additional attributes</span>
<span class="sd">    ---------------------</span>
<span class="sd">    k_flows : int</span>
<span class="sd">        Number of flows to use in the nonlinear unmixing function. Default: 1.</span>
<span class="sd">    net_hidden_dim : int</span>
<span class="sd">        Hidden dimension of the neural network used in the nonlinear unmixing function. Default: 128.</span>
<span class="sd">    net_hidden_layers : int</span>
<span class="sd">        Number of hidden layers of the neural network used in the nonlinear unmixing function. Default: 3.</span>
<span class="sd">    fix_mechanisms : bool</span>
<span class="sd">        Some mechanisms can be fixed to a simple gaussian distribution without loss of generality.</span>
<span class="sd">        This has only an effect for the parametric base distribution. If True, these mechanisms are fixed.</span>
<span class="sd">        Default: True.</span>
<span class="sd">    fix_all_intervention_targets : bool</span>
<span class="sd">        When fixable mechanisms are fixed, this parameter determines whether all intervention targets</span>
<span class="sd">        are fixed (option 1) or all intervention targets which are non-root nodes together with all</span>
<span class="sd">        non-intervened root nodes (option 2). See documentation of ParamMultiEnvCausalDistribution</span>
<span class="sd">        for more details. Default: False.</span>
<span class="sd">    nonparametric_base_distr : bool</span>
<span class="sd">        Whether to use a nonparametric base distribution for the flows. If false, a parametric linear</span>
<span class="sd">        gaussian causal base distribution is used. Default: False.</span>
<span class="sd">    K_cbn : int</span>
<span class="sd">        Number of flows to use in the nonlinear nonparametric base distribution. Default: 3.</span>
<span class="sd">    net_hidden_dim_cbn : int</span>
<span class="sd">        Hidden dimension of the neural network used in the nonlinear nonparametric base distribution. Default: 128.</span>
<span class="sd">    net_hidden_layers_cbn : int</span>
<span class="sd">        Number of hidden layers of the neural network used in the nonlinear nonparametric base distribution. Default: 3.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">adjacency_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-2</span><span class="p">,</span>
        <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">lr_scheduler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">lr_min</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">adjacency_misspecified</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">k_flows</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">net_hidden_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
        <span class="n">net_hidden_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">fix_mechanisms</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">fix_all_intervention_targets</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">nonparametric_base_distr</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">K_cbn</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">net_hidden_dim_cbn</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
        <span class="n">net_hidden_layers_cbn</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span>
            <span class="n">adjacency_matrix</span><span class="o">=</span><span class="n">adjacency_matrix</span><span class="p">,</span>
            <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
            <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler</span><span class="p">,</span>
            <span class="n">lr_min</span><span class="o">=</span><span class="n">lr_min</span><span class="p">,</span>
            <span class="n">adjacency_misspecified</span><span class="o">=</span><span class="n">adjacency_misspecified</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">NonlinearCauCAEncoder</span><span class="p">(</span>
            <span class="n">latent_dim</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">,</span>  <span class="c1"># this is the misspecified adjacency matrix if adjacency_misspecified=True</span>
            <span class="n">K</span><span class="o">=</span><span class="n">k_flows</span><span class="p">,</span>
            <span class="n">intervention_targets_per_env</span><span class="o">=</span><span class="n">intervention_targets_per_env</span><span class="p">,</span>
            <span class="n">net_hidden_dim</span><span class="o">=</span><span class="n">net_hidden_dim</span><span class="p">,</span>
            <span class="n">net_hidden_layers</span><span class="o">=</span><span class="n">net_hidden_layers</span><span class="p">,</span>
            <span class="n">fix_mechanisms</span><span class="o">=</span><span class="n">fix_mechanisms</span><span class="p">,</span>
            <span class="n">fix_all_intervention_targets</span><span class="o">=</span><span class="n">fix_all_intervention_targets</span><span class="p">,</span>
            <span class="n">nonparametric_base_distr</span><span class="o">=</span><span class="n">nonparametric_base_distr</span><span class="p">,</span>
            <span class="n">K_cbn</span><span class="o">=</span><span class="n">K_cbn</span><span class="p">,</span>
            <span class="n">net_hidden_dim_cbn</span><span class="o">=</span><span class="n">net_hidden_dim_cbn</span><span class="p">,</span>
            <span class="n">net_hidden_layers_cbn</span><span class="o">=</span><span class="n">net_hidden_layers_cbn</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">




<h2 id="model.encoder" class="doc doc-heading">
          <code>encoder</code>


</h2>

  <div class="doc doc-contents ">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">




<h3 id="model.encoder.CauCAEncoder" class="doc doc-heading">
          <code>CauCAEncoder</code>


</h3>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><span title="normflows.NormalizingFlow">NormalizingFlow</span></code></p>

  
      <p>CauCA encoder for multi-environment data.</p>
<p>The encoder maps from the observed data x to the latent space v_hat. The latent space is
assumed to have causal structure. The encoder is trained to maximize the likelihood of
the data under the causal model. x and v_hat are assumed to have the same dimension.</p>

<details class="the-encoder-has-two-main-components" open>
  <summary>The encoder has two main components</summary>
  <ol>
<li>A causal base distribution q0 over the latent space. This encodes the latent
causal structure.</li>
<li>An unmixing function mapping from the observations to the latent space.</li>
</ol>
</details>      <h5 id="model.encoder.CauCAEncoder--attributes">Attributes</h5>
<p>latent_dim: int
    Dimension of the latent and observed variables.
adjacency_matrix: np.ndarray, shape (latent_dim, latent_dim)
    Adjacency matrix of the latent causal graph.
intervention_targets_per_env: Tensor, shape (no_envs, latent_dim)
    Which variables are intervened on in each environment.
fix_mechanisms: bool
    Whether to fix some fixable mechanisms in the causal model. (See documentation of the
    ParamMultiEnvCausalDistribution for details.) Default: False.
fix_all_intervention_targets: bool
    Whether to fix all intervention targets in the causal model. (See documentation of the
    ParamMultiEnvCausalDistribution for details.) Default: False.
nonparametric_base_distr: bool
    Whether to use a nonparametric base distribution. If False, a parametric base distribution
    assuming linear causal mechanisms is used. Default: False.
flows: Optional[list[nf.flows.Flow]]
    List of normalizing flows to use for the unmixing function. Default: None.
q0: Optional[nf.distributions.BaseDistribution]
    Base distribution over the latent space. Default: None.
K_cbn: int
    Number of normalizing flows to use for the nonparametric base distribution. Default: 3.
net_hidden_dim_cbn: int
    Hidden dimension of the neural network used in the nonparametric base distribution. Default: 128.
net_hidden_layers_cbn: int
    Number of hidden layers in the neural network used in the nonparametric base distribution. Default: 3.</p>
<h5 id="model.encoder.CauCAEncoder--methods">Methods</h5>
<p>multi_env_log_prob(x, e, intervention_targets) -&gt; Tensor
    Computes log probability of x in environment e.
forward(x) -&gt; Tensor
    Maps from the observed data x to the latent space v_hat.</p>

            <details class="quote">
              <summary>Source code in <code>model/encoder.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CauCAEncoder</span><span class="p">(</span><span class="n">nf</span><span class="o">.</span><span class="n">NormalizingFlow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    CauCA encoder for multi-environment data.</span>

<span class="sd">    The encoder maps from the observed data x to the latent space v_hat. The latent space is</span>
<span class="sd">    assumed to have causal structure. The encoder is trained to maximize the likelihood of</span>
<span class="sd">    the data under the causal model. x and v_hat are assumed to have the same dimension.</span>

<span class="sd">    The encoder has two main components:</span>
<span class="sd">        1. A causal base distribution q0 over the latent space. This encodes the latent</span>
<span class="sd">        causal structure.</span>
<span class="sd">        2. An unmixing function mapping from the observations to the latent space.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    latent_dim: int</span>
<span class="sd">        Dimension of the latent and observed variables.</span>
<span class="sd">    adjacency_matrix: np.ndarray, shape (latent_dim, latent_dim)</span>
<span class="sd">        Adjacency matrix of the latent causal graph.</span>
<span class="sd">    intervention_targets_per_env: Tensor, shape (no_envs, latent_dim)</span>
<span class="sd">        Which variables are intervened on in each environment.</span>
<span class="sd">    fix_mechanisms: bool</span>
<span class="sd">        Whether to fix some fixable mechanisms in the causal model. (See documentation of the</span>
<span class="sd">        ParamMultiEnvCausalDistribution for details.) Default: False.</span>
<span class="sd">    fix_all_intervention_targets: bool</span>
<span class="sd">        Whether to fix all intervention targets in the causal model. (See documentation of the</span>
<span class="sd">        ParamMultiEnvCausalDistribution for details.) Default: False.</span>
<span class="sd">    nonparametric_base_distr: bool</span>
<span class="sd">        Whether to use a nonparametric base distribution. If False, a parametric base distribution</span>
<span class="sd">        assuming linear causal mechanisms is used. Default: False.</span>
<span class="sd">    flows: Optional[list[nf.flows.Flow]]</span>
<span class="sd">        List of normalizing flows to use for the unmixing function. Default: None.</span>
<span class="sd">    q0: Optional[nf.distributions.BaseDistribution]</span>
<span class="sd">        Base distribution over the latent space. Default: None.</span>
<span class="sd">    K_cbn: int</span>
<span class="sd">        Number of normalizing flows to use for the nonparametric base distribution. Default: 3.</span>
<span class="sd">    net_hidden_dim_cbn: int</span>
<span class="sd">        Hidden dimension of the neural network used in the nonparametric base distribution. Default: 128.</span>
<span class="sd">    net_hidden_layers_cbn: int</span>
<span class="sd">        Number of hidden layers in the neural network used in the nonparametric base distribution. Default: 3.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    multi_env_log_prob(x, e, intervention_targets) -&gt; Tensor</span>
<span class="sd">        Computes log probability of x in environment e.</span>
<span class="sd">    forward(x) -&gt; Tensor</span>
<span class="sd">        Maps from the observed data x to the latent space v_hat.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">adjacency_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fix_mechanisms</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">fix_all_intervention_targets</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">nonparametric_base_distr</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">flows</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">nf</span><span class="o">.</span><span class="n">flows</span><span class="o">.</span><span class="n">Flow</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">q0</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nf</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">BaseDistribution</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">K_cbn</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">net_hidden_dim_cbn</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
        <span class="n">net_hidden_layers_cbn</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">latent_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adjacency_matrix</span> <span class="o">=</span> <span class="n">adjacency_matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intervention_targets_per_env</span> <span class="o">=</span> <span class="n">intervention_targets_per_env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fix_mechanisms</span> <span class="o">=</span> <span class="n">fix_mechanisms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fix_all_intervention_targets</span> <span class="o">=</span> <span class="n">fix_all_intervention_targets</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nonparametric_base_distr</span> <span class="o">=</span> <span class="n">nonparametric_base_distr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K_cbn</span> <span class="o">=</span> <span class="n">K_cbn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net_hidden_dim_cbn</span> <span class="o">=</span> <span class="n">net_hidden_dim_cbn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net_hidden_layers_cbn</span> <span class="o">=</span> <span class="n">net_hidden_layers_cbn</span>

        <span class="k">if</span> <span class="n">q0</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonparametric_base_distr</span><span class="p">:</span>
                <span class="n">q0</span> <span class="o">=</span> <span class="n">NonparamMultiEnvCausalDistribution</span><span class="p">(</span>
                    <span class="n">adjacency_matrix</span><span class="o">=</span><span class="n">adjacency_matrix</span><span class="p">,</span>
                    <span class="n">K</span><span class="o">=</span><span class="n">K_cbn</span><span class="p">,</span>
                    <span class="n">net_hidden_dim</span><span class="o">=</span><span class="n">net_hidden_dim_cbn</span><span class="p">,</span>
                    <span class="n">net_hidden_layers</span><span class="o">=</span><span class="n">net_hidden_layers_cbn</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">assert</span> <span class="p">(</span>
                    <span class="n">intervention_targets_per_env</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="p">),</span> <span class="s2">&quot;intervention_targets_per_env must be provided for parametric base distribution&quot;</span>
                <span class="n">q0</span> <span class="o">=</span> <span class="n">ParamMultiEnvCausalDistribution</span><span class="p">(</span>
                    <span class="n">adjacency_matrix</span><span class="o">=</span><span class="n">adjacency_matrix</span><span class="p">,</span>
                    <span class="n">intervention_targets_per_env</span><span class="o">=</span><span class="n">intervention_targets_per_env</span><span class="p">,</span>
                    <span class="n">fix_mechanisms</span><span class="o">=</span><span class="n">fix_mechanisms</span><span class="p">,</span>
                    <span class="n">fix_all_intervention_targets</span><span class="o">=</span><span class="n">fix_all_intervention_targets</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">q0</span><span class="o">=</span><span class="n">q0</span><span class="p">,</span> <span class="n">flows</span><span class="o">=</span><span class="n">flows</span> <span class="k">if</span> <span class="n">flows</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[])</span>

    <span class="k">def</span> <span class="nf">multi_env_log_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">intervention_targets</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>

<div class="doc doc-object doc-class">




<h3 id="model.encoder.LinearCauCAEncoder" class="doc doc-heading">
          <code>LinearCauCAEncoder</code>


</h3>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="model.encoder.CauCAEncoder" href="#model.encoder.CauCAEncoder">CauCAEncoder</a></code></p>

  
      <p>Linear CauCA encoder for multi-environment data.</p>

            <details class="quote">
              <summary>Source code in <code>model/encoder.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">LinearCauCAEncoder</span><span class="p">(</span><span class="n">CauCAEncoder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Linear CauCA encoder for multi-environment data.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">adjacency_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fix_mechanisms</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">fix_all_intervention_targets</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">nonparametric_base_distr</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span>
            <span class="n">adjacency_matrix</span><span class="o">=</span><span class="n">adjacency_matrix</span><span class="p">,</span>
            <span class="n">intervention_targets_per_env</span><span class="o">=</span><span class="n">intervention_targets_per_env</span><span class="p">,</span>
            <span class="n">fix_mechanisms</span><span class="o">=</span><span class="n">fix_mechanisms</span><span class="p">,</span>
            <span class="n">fix_all_intervention_targets</span><span class="o">=</span><span class="n">fix_all_intervention_targets</span><span class="p">,</span>
            <span class="n">nonparametric_base_distr</span><span class="o">=</span><span class="n">nonparametric_base_distr</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unmixing</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">multi_env_log_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">intervention_targets</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]]:</span>
        <span class="n">v_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">jacobian</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">jacobian</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">unmixing</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">det</span><span class="p">(</span><span class="n">jacobian</span><span class="p">)))</span>
        <span class="n">determinant_terms</span> <span class="o">=</span> <span class="n">log_q</span>

        <span class="n">prob_terms</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">multi_env_log_prob</span><span class="p">(</span><span class="n">v_hat</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">intervention_targets</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">prob_terms</span>
        <span class="n">res</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;log_prob&quot;</span><span class="p">:</span> <span class="n">log_q</span><span class="p">,</span>
            <span class="s2">&quot;determinant_terms&quot;</span><span class="p">:</span> <span class="n">determinant_terms</span><span class="p">,</span>
            <span class="s2">&quot;prob_terms&quot;</span><span class="p">:</span> <span class="n">prob_terms</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="n">log_q</span><span class="p">,</span> <span class="n">res</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">latent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unmixing</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">latent</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>

<div class="doc doc-object doc-class">




<h3 id="model.encoder.NaiveEncoder" class="doc doc-heading">
          <code>NaiveEncoder</code>


</h3>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="model.encoder.NonlinearCauCAEncoder" href="#model.encoder.NonlinearCauCAEncoder">NonlinearCauCAEncoder</a></code></p>

  
      <p>Naive encoder for multi-environment data.</p>
<p>This encoder does not assume any causal structure in the latent space. Equivalent to independent
components analysis (ICA).</p>

            <details class="quote">
              <summary>Source code in <code>model/encoder.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">NaiveEncoder</span><span class="p">(</span><span class="n">NonlinearCauCAEncoder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Naive encoder for multi-environment data.</span>

<span class="sd">    This encoder does not assume any causal structure in the latent space. Equivalent to independent</span>
<span class="sd">    components analysis (ICA).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">adjacency_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">K</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">net_hidden_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
        <span class="n">net_hidden_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># overwrite the q0 from NonlinearICAEncoder</span>
        <span class="n">q0</span> <span class="o">=</span> <span class="n">NaiveMultiEnvCausalDistribution</span><span class="p">(</span>
            <span class="n">adjacency_matrix</span><span class="o">=</span><span class="n">adjacency_matrix</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span>
            <span class="n">adjacency_matrix</span><span class="o">=</span><span class="n">adjacency_matrix</span><span class="p">,</span>
            <span class="n">K</span><span class="o">=</span><span class="n">K</span><span class="p">,</span>
            <span class="n">intervention_targets_per_env</span><span class="o">=</span><span class="n">intervention_targets_per_env</span><span class="p">,</span>
            <span class="n">net_hidden_dim</span><span class="o">=</span><span class="n">net_hidden_dim</span><span class="p">,</span>
            <span class="n">net_hidden_layers</span><span class="o">=</span><span class="n">net_hidden_layers</span><span class="p">,</span>
            <span class="n">q0</span><span class="o">=</span><span class="n">q0</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>

<div class="doc doc-object doc-class">




<h3 id="model.encoder.NonlinearCauCAEncoder" class="doc doc-heading">
          <code>NonlinearCauCAEncoder</code>


</h3>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="model.encoder.CauCAEncoder" href="#model.encoder.CauCAEncoder">CauCAEncoder</a></code></p>

  
      <p>Nonlinear CauCA encoder for multi-environment data.</p>
<p>Here the unmixing function is a normalizing flow.</p>
<h5 id="model.encoder.NonlinearCauCAEncoder--parameters">Parameters</h5>
<p>latent_dim: int
    Dimension of the latent and observed variables.
adjacency_matrix: np.ndarray, shape (latent_dim, latent_dim)
    Adjacency matrix of the latent causal graph.
K: int
    Number of normalizing flows to use for the unmixing function. Default: 1.
intervention_targets_per_env: Tensor, shape (no_envs, latent_dim)
    Which variables are intervened on in each environment.
net_hidden_dim: int
    Hidden dimension of the neural network used in the normalizing flows. Default: 128.
net_hidden_layers: int
    Number of hidden layers in the neural network used in the normalizing flows. Default: 3.
q0: Optional[nf.distributions.BaseDistribution]
    Base distribution over the latent space. Default: None.
K_cbn: int
    Number of normalizing flows to use for the nonparametric base distribution. Default: 3.
net_hidden_dim_cbn: int
    Hidden dimension of the neural network used in the nonparametric base distribution. Default: 128.
net_hidden_layers_cbn: int
    Number of hidden layers in the neural network used in the nonparametric base distribution. Default: 3.</p>

            <details class="quote">
              <summary>Source code in <code>model/encoder.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">NonlinearCauCAEncoder</span><span class="p">(</span><span class="n">CauCAEncoder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Nonlinear CauCA encoder for multi-environment data.</span>

<span class="sd">    Here the unmixing function is a normalizing flow.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    latent_dim: int</span>
<span class="sd">        Dimension of the latent and observed variables.</span>
<span class="sd">    adjacency_matrix: np.ndarray, shape (latent_dim, latent_dim)</span>
<span class="sd">        Adjacency matrix of the latent causal graph.</span>
<span class="sd">    K: int</span>
<span class="sd">        Number of normalizing flows to use for the unmixing function. Default: 1.</span>
<span class="sd">    intervention_targets_per_env: Tensor, shape (no_envs, latent_dim)</span>
<span class="sd">        Which variables are intervened on in each environment.</span>
<span class="sd">    net_hidden_dim: int</span>
<span class="sd">        Hidden dimension of the neural network used in the normalizing flows. Default: 128.</span>
<span class="sd">    net_hidden_layers: int</span>
<span class="sd">        Number of hidden layers in the neural network used in the normalizing flows. Default: 3.</span>
<span class="sd">    q0: Optional[nf.distributions.BaseDistribution]</span>
<span class="sd">        Base distribution over the latent space. Default: None.</span>
<span class="sd">    K_cbn: int</span>
<span class="sd">        Number of normalizing flows to use for the nonparametric base distribution. Default: 3.</span>
<span class="sd">    net_hidden_dim_cbn: int</span>
<span class="sd">        Hidden dimension of the neural network used in the nonparametric base distribution. Default: 128.</span>
<span class="sd">    net_hidden_layers_cbn: int</span>
<span class="sd">        Number of hidden layers in the neural network used in the nonparametric base distribution. Default: 3.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">adjacency_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">K</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">net_hidden_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
        <span class="n">net_hidden_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">fix_mechanisms</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">fix_all_intervention_targets</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">nonparametric_base_distr</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">q0</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nf</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">BaseDistribution</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">K_cbn</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">net_hidden_dim_cbn</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
        <span class="n">net_hidden_layers_cbn</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">=</span> <span class="n">K</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intervention_targets_per_env</span> <span class="o">=</span> <span class="n">intervention_targets_per_env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net_hidden_dim</span> <span class="o">=</span> <span class="n">net_hidden_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net_hidden_layers</span> <span class="o">=</span> <span class="n">net_hidden_layers</span>

        <span class="n">flows</span> <span class="o">=</span> <span class="n">make_spline_flows</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span> <span class="n">net_hidden_dim</span><span class="p">,</span> <span class="n">net_hidden_layers</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span>
            <span class="n">adjacency_matrix</span><span class="o">=</span><span class="n">adjacency_matrix</span><span class="p">,</span>
            <span class="n">intervention_targets_per_env</span><span class="o">=</span><span class="n">intervention_targets_per_env</span><span class="p">,</span>
            <span class="n">fix_mechanisms</span><span class="o">=</span><span class="n">fix_mechanisms</span><span class="p">,</span>
            <span class="n">fix_all_intervention_targets</span><span class="o">=</span><span class="n">fix_all_intervention_targets</span><span class="p">,</span>
            <span class="n">nonparametric_base_distr</span><span class="o">=</span><span class="n">nonparametric_base_distr</span><span class="p">,</span>
            <span class="n">flows</span><span class="o">=</span><span class="n">flows</span><span class="p">,</span>
            <span class="n">q0</span><span class="o">=</span><span class="n">q0</span><span class="p">,</span>
            <span class="n">K_cbn</span><span class="o">=</span><span class="n">K_cbn</span><span class="p">,</span>
            <span class="n">net_hidden_dim_cbn</span><span class="o">=</span><span class="n">net_hidden_dim_cbn</span><span class="p">,</span>
            <span class="n">net_hidden_layers_cbn</span><span class="o">=</span><span class="n">net_hidden_layers_cbn</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">multi_env_log_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">intervention_targets</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]]:</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>
        <span class="n">determinant_terms</span> <span class="o">=</span> <span class="n">log_q</span>
        <span class="n">prob_terms</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">multi_env_log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">intervention_targets</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">prob_terms</span>
        <span class="n">res</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;log_prob&quot;</span><span class="p">:</span> <span class="n">log_q</span><span class="p">,</span>
            <span class="s2">&quot;determinant_terms&quot;</span><span class="p">:</span> <span class="n">determinant_terms</span><span class="p">,</span>
            <span class="s2">&quot;prob_terms&quot;</span><span class="p">:</span> <span class="n">prob_terms</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="n">log_q</span><span class="p">,</span> <span class="n">res</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">




<h2 id="model.normalizing_flow" class="doc doc-heading">
          <code>normalizing_flow</code>


</h2>

  <div class="doc doc-contents ">

  

  <div class="doc doc-children">










<div class="doc doc-object doc-module">




<h3 id="model.normalizing_flow.distribution" class="doc doc-heading">
          <code>distribution</code>


</h3>

  <div class="doc doc-contents ">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">




<h4 id="model.normalizing_flow.distribution.MultiEnvCausalDistribution" class="doc doc-heading">
          <code>MultiEnvCausalDistribution</code>


</h4>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><span title="normflows.distributions.BaseDistribution">BaseDistribution</span></code>, <code><span title="abc.ABC">ABC</span></code></p>

  
      <p>Base class for parametric multi-environment causal distributions.</p>
<p>In typical normalizing flow architectures, the base distribution is a simple distribution
such as a multivariate Gaussian. In our case, the base distribution has additional multi-environment
causal structure. Hence, in the parametric case, this class learns the parameters of the causal
mechanisms and noise distributions. The causal graph is assumed to be known.</p>
<p>This is a subclass of BaseDistribution, which is a subclass of torch.nn.Module. Hence, this class
can be used as a base distribution in a normalizing flow.</p>
<h6 id="model.normalizing_flow.distribution.MultiEnvCausalDistribution--methods">Methods</h6>
<p>multi_env_log_prob(z, e, intervention_targets) -&gt; Tensor
    Compute the log probability of the latent variables v in environment e, given the intervention targets.
    This is used as the main training objective.</p>

            <details class="quote">
              <summary>Source code in <code>model/normalizing_flow/distribution.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MultiEnvCausalDistribution</span><span class="p">(</span><span class="n">nf</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">BaseDistribution</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for parametric multi-environment causal distributions.</span>

<span class="sd">    In typical normalizing flow architectures, the base distribution is a simple distribution</span>
<span class="sd">    such as a multivariate Gaussian. In our case, the base distribution has additional multi-environment</span>
<span class="sd">    causal structure. Hence, in the parametric case, this class learns the parameters of the causal</span>
<span class="sd">    mechanisms and noise distributions. The causal graph is assumed to be known.</span>

<span class="sd">    This is a subclass of BaseDistribution, which is a subclass of torch.nn.Module. Hence, this class</span>
<span class="sd">    can be used as a base distribution in a normalizing flow.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    multi_env_log_prob(z, e, intervention_targets) -&gt; Tensor</span>
<span class="sd">        Compute the log probability of the latent variables v in environment e, given the intervention targets.</span>
<span class="sd">        This is used as the main training objective.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">multi_env_log_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">intervention_targets</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>

<div class="doc doc-object doc-class">




<h4 id="model.normalizing_flow.distribution.NaiveMultiEnvCausalDistribution" class="doc doc-heading">
          <code>NaiveMultiEnvCausalDistribution</code>


</h4>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="model.normalizing_flow.distribution.MultiEnvCausalDistribution" href="#model.normalizing_flow.distribution.MultiEnvCausalDistribution">MultiEnvCausalDistribution</a></code></p>

  
      <p>Naive multi-environment causal distribution.</p>
<p>This is a dummy-version of ParamMultiEnvCausalDistribution, where the causal mechanisms are assumed to
be trivial (no connectioons between variables) and the noise distributions are assumed to be Gaussian
and independent of the environment. This is equivalent to the independent component analysis (ICA) case.</p>

            <details class="quote">
              <summary>Source code in <code>model/normalizing_flow/distribution.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">NaiveMultiEnvCausalDistribution</span><span class="p">(</span><span class="n">MultiEnvCausalDistribution</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Naive multi-environment causal distribution.</span>

<span class="sd">    This is a dummy-version of ParamMultiEnvCausalDistribution, where the causal mechanisms are assumed to</span>
<span class="sd">    be trivial (no connectioons between variables) and the noise distributions are assumed to be Gaussian</span>
<span class="sd">    and independent of the environment. This is equivalent to the independent component analysis (ICA) case.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">adjacency_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adjacency_matrix</span> <span class="o">=</span> <span class="n">adjacency_matrix</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">q0</span> <span class="o">=</span> <span class="n">DiagGaussian</span><span class="p">(</span><span class="n">adjacency_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">multi_env_log_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">intervention_targets</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>

<div class="doc doc-object doc-class">




<h4 id="model.normalizing_flow.distribution.ParamMultiEnvCausalDistribution" class="doc doc-heading">
          <code>ParamMultiEnvCausalDistribution</code>


</h4>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="model.normalizing_flow.distribution.MultiEnvCausalDistribution" href="#model.normalizing_flow.distribution.MultiEnvCausalDistribution">MultiEnvCausalDistribution</a></code></p>

  
      <p>Parametric multi-environment causal distribution.</p>
<p>This class learns the parameters of the causal mechanisms and noise distributions. The causal mechanisms
are assumed to be linear, and the noise distributions are assumed to be Gaussian. In environments where
a variable is intervened on, the connection to its parents is assumed to be cut off, and the noise distribution
can be shifted relative to the observational environment (when the variable is not intervened on).</p>
<p>Theoretically, we can fix some of the mechanisms involved w.l.o.g. and still achieve identifiability
(see Appendix G2 of [1]). There are two ways to do this:
    1. Fix all mechanisms that are intervened on.
    2. Fix all observational mechanisms with an empty parent set and all intervened mechanisms with a
    non-empty parent set.
However, we do not have to fix any of the mechanisms and in practice, we find that this leads to better
performance.</p>
<h6 id="model.normalizing_flow.distribution.ParamMultiEnvCausalDistribution--attributes">Attributes</h6>
<p>adjacency_matrix: np.ndarray
    Adjacency matrix of the causal graph.
fix_mechanisms: bool
    Whether to fix any of the mechanisms. Default: False.
fix_all_intervention_targets: bool
    Whether to fix all mechanisms that are intervened on (option 1 above). If False, we fix all observational
    mechanisms with an empty parent set and all intervened mechanisms with a non-empty parent set (option 2 above).
    Default: False.
intervention_targets_per_env: Tensor, shape (num_envs, latent_dim)
    Intervention targets per environment, with 1 indicating that the variable is intervened on
    and 0 indicating that the variable is not intervened on. This variable also implicitly defines
    the number of environments.
dag: nx.DiGraph
    Directed acyclic graph of the causal connections.
coeff_values: nn.ParameterList
    List of lists of coefficients for the linear mechanisms. The outer list has length equal to the number of
    variables, and the inner list has length equal to the number of parents of the variable. The last element
    of the inner list is the variance parameter. I.e. coeff_values[i][:-1] are the linear weights of the parent
    variables of variable i, and coeff_values[i][-1] is weight of the exogenous noise.
noise_means: nn.ParameterList
    List of lists of means for the noise distributions. The outer list has length equal to the number of
    environments, and the inner list has length equal to the number of variables. noise_means[e][i] is the mean
    of the noise distribution for variable i in environment e. Note that not all of these parameters are
    used in the computation of the log probability. If a variable i is not intervened on in environment e,
    we use the observational noise distribution, i.e. noise_means[0][i] (e=0 is assumed to be the
    observational environment).
noise_stds: nn.ParameterList
    Same as noise_means, but for the standard deviations of the noise distributions.
coeff_values_requires_grad: list[list[bool]]
    Whether each coefficient is trainable. This is used to fix the coefficients of the mechanisms.
noise_means_requires_grad: list[list[bool]]
    Whether each noise mean is trainable. This is used to fix the noise means of the mechanisms.
noise_stds_requires_grad: list[list[bool]]
    Whether each noise standard deviation is trainable. This is used to fix the noise standard deviations</p>
<h6 id="model.normalizing_flow.distribution.ParamMultiEnvCausalDistribution--references">References</h6>
<p>[1] https://arxiv.org/abs/2305.17225</p>

            <details class="quote">
              <summary>Source code in <code>model/normalizing_flow/distribution.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ParamMultiEnvCausalDistribution</span><span class="p">(</span><span class="n">MultiEnvCausalDistribution</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parametric multi-environment causal distribution.</span>

<span class="sd">    This class learns the parameters of the causal mechanisms and noise distributions. The causal mechanisms</span>
<span class="sd">    are assumed to be linear, and the noise distributions are assumed to be Gaussian. In environments where</span>
<span class="sd">    a variable is intervened on, the connection to its parents is assumed to be cut off, and the noise distribution</span>
<span class="sd">    can be shifted relative to the observational environment (when the variable is not intervened on).</span>

<span class="sd">    Theoretically, we can fix some of the mechanisms involved w.l.o.g. and still achieve identifiability</span>
<span class="sd">    (see Appendix G2 of [1]). There are two ways to do this:</span>
<span class="sd">        1. Fix all mechanisms that are intervened on.</span>
<span class="sd">        2. Fix all observational mechanisms with an empty parent set and all intervened mechanisms with a</span>
<span class="sd">        non-empty parent set.</span>
<span class="sd">    However, we do not have to fix any of the mechanisms and in practice, we find that this leads to better</span>
<span class="sd">    performance.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    adjacency_matrix: np.ndarray</span>
<span class="sd">        Adjacency matrix of the causal graph.</span>
<span class="sd">    fix_mechanisms: bool</span>
<span class="sd">        Whether to fix any of the mechanisms. Default: False.</span>
<span class="sd">    fix_all_intervention_targets: bool</span>
<span class="sd">        Whether to fix all mechanisms that are intervened on (option 1 above). If False, we fix all observational</span>
<span class="sd">        mechanisms with an empty parent set and all intervened mechanisms with a non-empty parent set (option 2 above).</span>
<span class="sd">        Default: False.</span>
<span class="sd">    intervention_targets_per_env: Tensor, shape (num_envs, latent_dim)</span>
<span class="sd">        Intervention targets per environment, with 1 indicating that the variable is intervened on</span>
<span class="sd">        and 0 indicating that the variable is not intervened on. This variable also implicitly defines</span>
<span class="sd">        the number of environments.</span>
<span class="sd">    dag: nx.DiGraph</span>
<span class="sd">        Directed acyclic graph of the causal connections.</span>
<span class="sd">    coeff_values: nn.ParameterList</span>
<span class="sd">        List of lists of coefficients for the linear mechanisms. The outer list has length equal to the number of</span>
<span class="sd">        variables, and the inner list has length equal to the number of parents of the variable. The last element</span>
<span class="sd">        of the inner list is the variance parameter. I.e. coeff_values[i][:-1] are the linear weights of the parent</span>
<span class="sd">        variables of variable i, and coeff_values[i][-1] is weight of the exogenous noise.</span>
<span class="sd">    noise_means: nn.ParameterList</span>
<span class="sd">        List of lists of means for the noise distributions. The outer list has length equal to the number of</span>
<span class="sd">        environments, and the inner list has length equal to the number of variables. noise_means[e][i] is the mean</span>
<span class="sd">        of the noise distribution for variable i in environment e. Note that not all of these parameters are</span>
<span class="sd">        used in the computation of the log probability. If a variable i is not intervened on in environment e,</span>
<span class="sd">        we use the observational noise distribution, i.e. noise_means[0][i] (e=0 is assumed to be the</span>
<span class="sd">        observational environment).</span>
<span class="sd">    noise_stds: nn.ParameterList</span>
<span class="sd">        Same as noise_means, but for the standard deviations of the noise distributions.</span>
<span class="sd">    coeff_values_requires_grad: list[list[bool]]</span>
<span class="sd">        Whether each coefficient is trainable. This is used to fix the coefficients of the mechanisms.</span>
<span class="sd">    noise_means_requires_grad: list[list[bool]]</span>
<span class="sd">        Whether each noise mean is trainable. This is used to fix the noise means of the mechanisms.</span>
<span class="sd">    noise_stds_requires_grad: list[list[bool]]</span>
<span class="sd">        Whether each noise standard deviation is trainable. This is used to fix the noise standard deviations</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] https://arxiv.org/abs/2305.17225</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">adjacency_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">fix_mechanisms</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">fix_all_intervention_targets</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adjacency_matrix</span> <span class="o">=</span> <span class="n">adjacency_matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fix_mechanisms</span> <span class="o">=</span> <span class="n">fix_mechanisms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fix_all_intervention_targets</span> <span class="o">=</span> <span class="n">fix_all_intervention_targets</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intervention_targets_per_env</span> <span class="o">=</span> <span class="n">intervention_targets_per_env</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dag</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">(</span><span class="n">adjacency_matrix</span><span class="p">)</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

        <span class="n">coeff_values</span><span class="p">,</span> <span class="n">coeff_values_requires_grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_initial_coeffs</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span> <span class="n">device</span>
        <span class="p">)</span>
        <span class="n">noise_means</span><span class="p">,</span> <span class="n">noise_means_requires_grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_initial_noise_means</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
            <span class="n">fix_mechanisms</span><span class="p">,</span>
            <span class="n">intervention_targets_per_env</span><span class="p">,</span>
            <span class="n">fix_all_intervention_targets</span><span class="p">,</span>
            <span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">noise_stds</span><span class="p">,</span> <span class="n">noise_stds_requires_grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_initial_noise_stds</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
            <span class="n">fix_mechanisms</span><span class="p">,</span>
            <span class="n">intervention_targets_per_env</span><span class="p">,</span>
            <span class="n">fix_all_intervention_targets</span><span class="p">,</span>
            <span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">coeff_values</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">(</span><span class="n">coeff_values</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_means</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">(</span><span class="n">noise_means</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_stds</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">(</span><span class="n">noise_stds</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">coeff_values_requires_grad</span> <span class="o">=</span> <span class="n">coeff_values_requires_grad</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_means_requires_grad</span> <span class="o">=</span> <span class="n">noise_means_requires_grad</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_stds_requires_grad</span> <span class="o">=</span> <span class="n">noise_stds_requires_grad</span>

    <span class="k">def</span> <span class="nf">multi_env_log_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">intervention_targets</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">env</span> <span class="ow">in</span> <span class="n">e</span><span class="o">.</span><span class="n">unique</span><span class="p">():</span>
            <span class="n">env_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">e</span> <span class="o">==</span> <span class="n">env</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">z_env</span> <span class="o">=</span> <span class="n">z</span><span class="p">[</span><span class="n">env_mask</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">intervention_targets_env</span> <span class="o">=</span> <span class="n">intervention_targets</span><span class="p">[</span><span class="n">env_mask</span><span class="p">,</span> <span class="p">:]</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">parents</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dag</span><span class="o">.</span><span class="n">predecessors</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>

                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">intervention_targets_env</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">parent_contribution</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">coeffs_raw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coeff_values</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">coeffs_raw</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">):</span>
                        <span class="n">coeffs_raw</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">coeffs_raw</span><span class="p">])</span>
                    <span class="n">parent_coeffs</span> <span class="o">=</span> <span class="n">coeffs_raw</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">parent_contribution</span> <span class="o">=</span> <span class="n">parent_coeffs</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">z_env</span><span class="p">[:,</span> <span class="n">parents</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

                <span class="n">noise_env_idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">env</span><span class="p">)</span> <span class="k">if</span> <span class="n">intervention_targets_env</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span>
                <span class="n">var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_stds</span><span class="p">[</span><span class="n">noise_env_idx</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span>
                    <span class="n">z_env</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="n">noise_coeff</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coeff_values</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">noise_contribution</span> <span class="o">=</span> <span class="n">noise_coeff</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_means</span><span class="p">[</span><span class="n">noise_env_idx</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
                <span class="n">var</span> <span class="o">*=</span> <span class="n">noise_coeff</span> <span class="o">**</span> <span class="mi">2</span>

                <span class="n">log_p</span><span class="p">[</span><span class="n">env_mask</span><span class="p">]</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span>
                    <span class="n">parent_contribution</span> <span class="o">+</span> <span class="n">noise_contribution</span><span class="p">,</span> <span class="n">var</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
                <span class="p">)</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">z_env</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">log_p</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_set_initial_coeffs</span><span class="p">(</span>
        <span class="n">dag</span><span class="p">:</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">ParameterList</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]]:</span>
        <span class="n">coeff_values</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">coeff_values_requires_grad</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dag</span><span class="o">.</span><span class="n">number_of_nodes</span><span class="p">()):</span>
            <span class="n">coeff_values_i</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">coeff_values_requires_grad_i</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">num_parents</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">dag</span><span class="o">.</span><span class="n">predecessors</span><span class="p">(</span><span class="n">i</span><span class="p">)))</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_parents</span><span class="p">):</span>
                <span class="n">random_val</span> <span class="o">=</span> <span class="n">Uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">1</span><span class="p">,))</span>
                <span class="n">val</span> <span class="o">=</span> <span class="n">random_val</span>
                <span class="n">param</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">val</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">coeff_values_i</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
                <span class="n">coeff_values_requires_grad_i</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">const</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># variance param</span>
            <span class="n">coeff_values_i</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">const</span><span class="p">)</span>
            <span class="n">coeff_values_requires_grad_i</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">coeff_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">(</span><span class="n">coeff_values_i</span><span class="p">))</span>
            <span class="n">coeff_values_requires_grad</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">coeff_values_requires_grad_i</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">coeff_values</span><span class="p">,</span> <span class="n">coeff_values_requires_grad</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_set_initial_noise_means</span><span class="p">(</span>
        <span class="n">dag</span><span class="p">:</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">,</span>
        <span class="n">fix_mechanisms</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">fix_all_intervention_targets</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">ParameterList</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]]:</span>
        <span class="n">noise_means</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">noise_means_requires_grad</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">num_envs</span> <span class="o">=</span> <span class="n">intervention_targets_per_env</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_envs</span><span class="p">):</span>
            <span class="n">noise_means_e</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">noise_means_requires_grad_e</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dag</span><span class="o">.</span><span class="n">number_of_nodes</span><span class="p">()):</span>
                <span class="n">is_shifted</span> <span class="o">=</span> <span class="n">intervention_targets_per_env</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
                <span class="n">is_root</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">dag</span><span class="o">.</span><span class="n">predecessors</span><span class="p">(</span><span class="n">i</span><span class="p">)))</span> <span class="o">==</span> <span class="mi">0</span>
                <span class="k">if</span> <span class="n">fix_all_intervention_targets</span><span class="p">:</span>
                    <span class="n">is_fixed</span> <span class="o">=</span> <span class="n">is_shifted</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">is_fixed</span> <span class="o">=</span> <span class="p">(</span><span class="n">is_shifted</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_root</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
                        <span class="ow">not</span> <span class="n">is_shifted</span> <span class="ow">and</span> <span class="n">is_root</span>
                    <span class="p">)</span>
                <span class="n">is_fixed</span> <span class="o">=</span> <span class="n">is_fixed</span> <span class="ow">and</span> <span class="n">fix_mechanisms</span>
                <span class="n">random_val</span> <span class="o">=</span> <span class="n">Uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">1</span><span class="p">,))</span>
                <span class="n">val</span> <span class="o">=</span> <span class="n">random_val</span>
                <span class="n">param</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">val</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="ow">not</span> <span class="n">is_fixed</span><span class="p">)</span>
                <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">noise_means_e</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
                <span class="n">noise_means_requires_grad_e</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="ow">not</span> <span class="n">is_fixed</span><span class="p">)</span>
            <span class="n">noise_means</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">(</span><span class="n">noise_means_e</span><span class="p">))</span>
            <span class="n">noise_means_requires_grad</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">noise_means_requires_grad_e</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">noise_means</span><span class="p">,</span> <span class="n">noise_means_requires_grad</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_set_initial_noise_stds</span><span class="p">(</span>
        <span class="n">dag</span><span class="p">:</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">,</span>
        <span class="n">fix_mechanisms</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">intervention_targets_per_env</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">fix_all_intervention_targets</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">ParameterList</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]]:</span>
        <span class="n">noise_stds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">noise_stds_requires_grad</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">intervention_targets_per_env</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">noise_stds_e</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">noise_stds_requires_grad_e</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dag</span><span class="o">.</span><span class="n">number_of_nodes</span><span class="p">()):</span>
                <span class="n">is_shifted</span> <span class="o">=</span> <span class="n">intervention_targets_per_env</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
                <span class="n">is_root</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">dag</span><span class="o">.</span><span class="n">predecessors</span><span class="p">(</span><span class="n">i</span><span class="p">)))</span> <span class="o">==</span> <span class="mi">0</span>
                <span class="k">if</span> <span class="n">fix_all_intervention_targets</span><span class="p">:</span>
                    <span class="n">is_fixed</span> <span class="o">=</span> <span class="n">is_shifted</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">is_fixed</span> <span class="o">=</span> <span class="p">(</span><span class="n">is_shifted</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_root</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
                        <span class="ow">not</span> <span class="n">is_shifted</span> <span class="ow">and</span> <span class="n">is_root</span>
                    <span class="p">)</span>
                <span class="n">is_fixed</span> <span class="o">=</span> <span class="n">is_fixed</span> <span class="ow">and</span> <span class="n">fix_mechanisms</span>
                <span class="n">random_val</span> <span class="o">=</span> <span class="n">Uniform</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">1</span><span class="p">,))</span>
                <span class="n">val</span> <span class="o">=</span> <span class="n">random_val</span>
                <span class="n">param</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">val</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="ow">not</span> <span class="n">is_fixed</span><span class="p">)</span>
                <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">noise_stds_e</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
                <span class="n">noise_stds_requires_grad_e</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="ow">not</span> <span class="n">is_fixed</span><span class="p">)</span>
            <span class="n">noise_stds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">(</span><span class="n">noise_stds_e</span><span class="p">))</span>
            <span class="n">noise_stds_requires_grad</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">noise_stds_requires_grad_e</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">noise_stds</span><span class="p">,</span> <span class="n">noise_stds_requires_grad</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">




<h3 id="model.normalizing_flow.nonparametric_distribution" class="doc doc-heading">
          <code>nonparametric_distribution</code>


</h3>

  <div class="doc doc-contents ">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">




<h4 id="model.normalizing_flow.nonparametric_distribution.MultiEnvBaseDistribution" class="doc doc-heading">
          <code>MultiEnvBaseDistribution</code>


</h4>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><span title="normflows.distributions.BaseDistribution">BaseDistribution</span></code></p>

  
      <p>Base distribution for nonparametric multi-environment causal distributions.</p>
<p>This simple independent Gaussian distribution is used as the base distribution for the
nonparametric multi-environment causal distribution. I.e. this distribution represents the
exogenous noise in the SCM.</p>

            <details class="quote">
              <summary>Source code in <code>model/normalizing_flow/nonparametric_distribution.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MultiEnvBaseDistribution</span><span class="p">(</span><span class="n">nf</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">BaseDistribution</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base distribution for nonparametric multi-environment causal distributions.</span>

<span class="sd">    This simple independent Gaussian distribution is used as the base distribution for the</span>
<span class="sd">    nonparametric multi-environment causal distribution. I.e. this distribution represents the</span>
<span class="sd">    exogenous noise in the SCM.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">multi_env_log_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">intervention_targets</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">gaussian_nll</span> <span class="o">=</span> <span class="n">gaussian_nll_loss</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">full</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;none&quot;</span>
        <span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="o">~</span><span class="n">intervention_targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
        <span class="n">log_p</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">mask</span> <span class="o">*</span> <span class="n">gaussian_nll</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log_p</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>

<div class="doc doc-object doc-class">




<h4 id="model.normalizing_flow.nonparametric_distribution.NonparamMultiEnvCausalDistribution" class="doc doc-heading">
          <code>NonparamMultiEnvCausalDistribution</code>


</h4>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><span title="normflows.NormalizingFlow">NormalizingFlow</span></code></p>

  
      <p>Nonarametric multi-environment causal distribution.</p>
<p>A nonparametric causal distribution that uses a normalizing flow to parameterize the latent
causal mechanisms. This causal distribution has two parts:
    1. The latent SCM, which is parameterized by a normalizing flow. It represents the reduced
    form of the SCM, mapping independent (Gaussian) exogenous noise to the endogenous latent
    variables. The causal structure of the latent SCM is encoded through the topological order
    of the latent variables according to the adjacency matrix.
    2. Fixed, simple base distributions for the mechanisms that are intervened on.</p>
<h6 id="model.normalizing_flow.nonparametric_distribution.NonparamMultiEnvCausalDistribution--attributes">Attributes</h6>
<p>adjacency_matrix : np.ndarray
    The adjacency matrix of the SCM.
K : int
    The number of normalizing flow blocks to use for the reduced form of the SCM.
net_hidden_dim : int
    The hidden dimension of the neural networks used in the normalizing flow blocks.
net_hidden_layers : int
    The number of hidden layers of the neural networks used in the normalizing flow blocks.
perm : torch.Tensor
    The permutation of the latent variables according to the topological order.</p>
<h6 id="model.normalizing_flow.nonparametric_distribution.NonparamMultiEnvCausalDistribution--methods">Methods</h6>
<p>multi_env_log_prob(z, e, intervention_targets) -&gt; torch.Tensor
    Compute the log probability of the given data.</p>
<h6 id="model.normalizing_flow.nonparametric_distribution.NonparamMultiEnvCausalDistribution--references">References</h6>
<p>[1] https://arxiv.org/abs/2305.17225</p>

            <details class="quote">
              <summary>Source code in <code>model/normalizing_flow/nonparametric_distribution.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">NonparamMultiEnvCausalDistribution</span><span class="p">(</span><span class="n">nf</span><span class="o">.</span><span class="n">NormalizingFlow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Nonarametric multi-environment causal distribution.</span>

<span class="sd">    A nonparametric causal distribution that uses a normalizing flow to parameterize the latent</span>
<span class="sd">    causal mechanisms. This causal distribution has two parts:</span>
<span class="sd">        1. The latent SCM, which is parameterized by a normalizing flow. It represents the reduced</span>
<span class="sd">        form of the SCM, mapping independent (Gaussian) exogenous noise to the endogenous latent</span>
<span class="sd">        variables. The causal structure of the latent SCM is encoded through the topological order</span>
<span class="sd">        of the latent variables according to the adjacency matrix.</span>
<span class="sd">        2. Fixed, simple base distributions for the mechanisms that are intervened on.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    adjacency_matrix : np.ndarray</span>
<span class="sd">        The adjacency matrix of the SCM.</span>
<span class="sd">    K : int</span>
<span class="sd">        The number of normalizing flow blocks to use for the reduced form of the SCM.</span>
<span class="sd">    net_hidden_dim : int</span>
<span class="sd">        The hidden dimension of the neural networks used in the normalizing flow blocks.</span>
<span class="sd">    net_hidden_layers : int</span>
<span class="sd">        The number of hidden layers of the neural networks used in the normalizing flow blocks.</span>
<span class="sd">    perm : torch.Tensor</span>
<span class="sd">        The permutation of the latent variables according to the topological order.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    multi_env_log_prob(z, e, intervention_targets) -&gt; torch.Tensor</span>
<span class="sd">        Compute the log probability of the given data.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] https://arxiv.org/abs/2305.17225</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">adjacency_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">K</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">net_hidden_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
        <span class="n">net_hidden_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adjacency_matrix</span> <span class="o">=</span> <span class="n">adjacency_matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">=</span> <span class="n">K</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net_hidden_dim</span> <span class="o">=</span> <span class="n">net_hidden_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net_hidden_layers</span> <span class="o">=</span> <span class="n">net_hidden_layers</span>

        <span class="n">latent_dim</span> <span class="o">=</span> <span class="n">adjacency_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># permutation according to topological order</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">perm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
            <span class="nb">list</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">topological_sort</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">))),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">flows</span> <span class="o">=</span> <span class="n">make_spline_flows</span><span class="p">(</span>
            <span class="n">K</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span> <span class="n">net_hidden_dim</span><span class="p">,</span> <span class="n">net_hidden_layers</span><span class="p">,</span> <span class="n">permutation</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="n">q0</span> <span class="o">=</span> <span class="n">MultiEnvBaseDistribution</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">q0</span><span class="o">=</span><span class="n">q0</span><span class="p">,</span> <span class="n">flows</span><span class="o">=</span><span class="n">flows</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">multi_env_log_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">intervention_targets</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">perm</span><span class="p">]</span>  <span class="c1"># permute inputs to be in topological order</span>
        <span class="n">log_q</span><span class="p">,</span> <span class="n">u</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_determinant_terms</span><span class="p">(</span><span class="n">intervention_targets</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
        <span class="n">prob_terms</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q0</span><span class="o">.</span><span class="n">multi_env_log_prob</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">intervention_targets</span><span class="p">)</span>
        <span class="n">prob_terms_intervened</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prob_terms_intervened</span><span class="p">(</span><span class="n">intervention_targets</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
        <span class="n">log_q</span> <span class="o">+=</span> <span class="n">prob_terms</span> <span class="o">+</span> <span class="n">prob_terms_intervened</span>

        <span class="k">return</span> <span class="n">log_q</span>

    <span class="k">def</span> <span class="nf">_determinant_terms</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">intervention_targets</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
        <span class="n">log_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">z</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">u</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flows</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
            <span class="n">log_q</span> <span class="o">+=</span> <span class="n">log_det</span>

        <span class="c1"># remove determinant terms for intervened mechanisms</span>
        <span class="n">jac_row</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">jvp</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inverse</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">intervention_targets</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">jac_diag_element</span> <span class="o">=</span> <span class="p">(</span><span class="n">jac_row</span> <span class="o">*</span> <span class="n">intervention_targets</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># mask zero elements</span>
        <span class="n">not_intervened_mask</span> <span class="o">=</span> <span class="o">~</span><span class="n">intervention_targets</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
        <span class="n">jac_diag_element</span><span class="p">[</span><span class="n">not_intervened_mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">log_q</span> <span class="o">-=</span> <span class="n">log</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">jac_diag_element</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log_q</span><span class="p">,</span> <span class="n">u</span>

    <span class="k">def</span> <span class="nf">_prob_terms_intervened</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">intervention_targets</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the probability terms for the intervened mechanisms.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">gaussian_nll</span> <span class="o">=</span> <span class="n">gaussian_nll_loss</span><span class="p">(</span>
            <span class="n">z</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">full</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;none&quot;</span>
        <span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">intervention_targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
        <span class="n">prob_terms_intervention_targets</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">mask</span> <span class="o">*</span> <span class="n">gaussian_nll</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">prob_terms_intervention_targets</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>




  </div>

  </div>

</div>


  </div>

  </div>

</div>


  </div>

  </div>

</div></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../js/jquery-3.6.0.min.js"></script>
        <script src="../js/bootstrap.min.js"></script>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js"></script>
        <script src="../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
